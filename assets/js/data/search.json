[ { "title": "Building Linux From Scratch: A Journey into the Heart of Linux", "url": "/posts/building-linux-from-scratch/", "categories": "linux", "tags": "linux", "date": "2025-05-06 10:05:00 +0200", "snippet": "IntroductionAfter over a decade of using Linux, primarily Ubuntu, I felt it was time to delve deeper into the system‚Äôs internals. My goal was to understand how Linux operates beneath the surface, beyond the convenience of package managers and pre-configured environments. This curiosity led me to embark on the Linux From Scratch (LFS) project, a challenging yet rewarding experience that offers a comprehensive understanding of Linux‚Äôs core components.Motivation and BackgroundHaving used distributions like Ubuntu, Debian, and Fedora, I was comfortable with Linux‚Äôs user-facing aspects. However, I realized that to truly grasp the system‚Äôs workings, I needed to build it from the ground up. LFS presented itself as the perfect opportunity to achieve this, providing a step-by-step guide to constructing a Linux system entirely from source code.Preparation and SetupInitially, I was hesitant about starting LFS, questioning whether it was the right path. However, after reading positive reviews and experiences online, I decided to proceed. I followed the official LFS book closely and occasionally consulted Reddit for solutions to specific issues.For the build environment, I used VirtualBox with a Debian host system. Setting up the virtual machine posed challenges, particularly with partitioning. I encountered issues that led to 2 failed attempts before successfully configuring the partitions correctly.Building the SystemI opted for LFS version 12.3 with systemd (link to latest stable systemd LFS). The build process spanned approximately three weeks, as I worked on it intermittently. Following the book meticulously, I encountered difficulties, especially during the kernel compilation phase. To safeguard my progress, I took snapshots of the virtual machine, allowing me to revert to stable states when necessary.An invaluable resource during this phase was the Kernotex YouTube channel. The creator‚Äôs detailed explanations and walkthroughs provided clarity on complex steps, supplementing the information in the LFS book.Post-Build ConfigurationUpon completing the base LFS system, I refrained from adding additional software immediately. My focus was on ensuring the system booted correctly and functioned as intended. A notable hiccup occurred when I misconfigured GRUB, causing it to boot the kernel from the Debian host instead of the custom-compiled one. This misconfiguration led to unexpected behavior until I rectified the GRUB settings, after which the system operated smoothly.Reflections and InsightsThe most significant lesson from this experience was the importance of thoroughly reading documentation and understanding each command‚Äôs purpose. Merely copying and pasting commands without comprehension diminishes the learning experience. This project deepened my appreciation for the complexity and elegance of Linux, highlighting the immense effort invested in its development over the years.While I found the LFS journey enlightening, I recognize that it‚Äôs not for everyone. The process is time-consuming and can be overwhelming, especially for those without prior Linux experience. However, for individuals passionate about understanding Linux at a fundamental level, LFS offers unparalleled insights.ConclusionEmbarking on the LFS project was a transformative experience that enriched my understanding of Linux. It challenged me to engage with the system‚Äôs core components, fostering a deeper appreciation for its architecture and design. For those seeking to explore Linux beyond the surface, LFS serves as both a rigorous challenge and a rewarding educational endeavor." }, { "title": "Scout Rule", "url": "/posts/scout-rule/", "categories": "best-practices", "tags": "best-practices", "date": "2024-07-28 00:05:00 +0200", "snippet": "The ‚ÄúScout Rule‚Äù is derived from the Boy Scouts‚Äô motto: ‚ÄúLeave the campground cleaner than you found it.‚Äù In the context of software development, it emphasizes the idea of leaving the codebase better than it was before you worked on it. ‚ÄúAlways leave the campground cleaner than you found it‚Äù (boyscout rule)The same can be applied to many other fields, I will refer to software development here. Even if that is not related to your current task, you should watch out for possible improvements.It can be translated as: ‚ÄúAlways leave the code cleaner than you found it‚ÄùHere are some suggestions: If you notice mistakes in the surrounding code fix them right away If the class/method is getting bloated, think about refactoring If you come across outdated comments you should update, delete, or mark them as outdated Clean up unused methods/variables/classesOver time you can make this a habit, so it becomes easier." }, { "title": "Echoing Variables in Linux with newlines", "url": "/posts/echoing-variables-in-linux-with-newlines/", "categories": "bash", "tags": "bash", "date": "2024-07-20 15:22:00 +0200", "snippet": "In Linux, a common pattern is to pipe data from one program to the other using pipe operator |. Sometimes your script grows large and then you save intermediary results to variables to better handle processing logic.Depending on the terminal you use, it can happen that once you echo a variable it loses empty lines:var=\"line1line2line3\"echo $var# line1 line2 line3Quick AnswerJust wrap your variable in a double-quoted string!var=\"line1line2line3\"echo \"$var\"# line1# line2# line3Why does it happen?If a variable is used without double quotes, they are expanding in the following way: using IFS content is split into separate words (here newlines are usually lost due to IFS defaults, check note) The Internal Field Separator (IFS) is a special shell variable in Bash that determines how words are split when the shell interprets input. By default, IFS is set to a space, tab, and newline. each of the words will be substituted with pathname expansion, where wildcards such as * are expanding to files that match the condition Wildcards that are supported for path expansion: * - Matches any string, including the null string ? - Matches any single (one) character. [‚Ä¶] - Matches any one of the enclosed characters. only then all the results are passed to a command such as the echo for printing on a terminalWhen path expansion does matterLet‚Äôs say that you have some comment as the value of your variable and you would like to echo it out:var=\"/* Copyright 2024 */\"echo $var# /0 /bin /boot /cdrom /dev /etc /home /lib /lib32 /lib64 /libx32 /lost+found /media /mnt /opt /proc /root /run /sbin /snap /srv /swapfile /sys /tmp /usr /var Copyright 2024 bin/ boot/ cdrom/ dev/ etc/ home/ lib/ lib32/ lib64/ libx32/ lost+found/ media/ mnt/ opt/ proc/ root/ run/ sbin/ snap/ srv/ sys/ tmp/ usr/ var/Now it‚Äôs obvious that not only it‚Äôs unpredictable, but also dangerous to expand variables for arbitrary Linux commands/programs.How double quotes are helping?When the variable is put inside double quotes it will be substituted for its exact value.Since it‚Äôs part of the string, there are no substitutions and path expansions.var=\"/* Copyright 2024 */\"echo \"$var\"# /* Copyright 2024 */ In case you expect anything more than a single word that doesn‚Äôt have special characters, you should enclose variable in double quotes when evaluating its content" }, { "title": "The Millennium Bug's Little Brother: Y2038", "url": "/posts/the-millennium-bug-s-little-brother-y2038/", "categories": "bugs", "tags": "bugs", "date": "2024-07-14 21:06:00 +0200", "snippet": "Remember the year 2000? If you were around, you might recall the sheer panic that gripped the world as we approached the end of 1999. People stocked up on canned beans and bottled water like they were preparing for a zombie apocalypse. Why? Because of a little thing called the Y2K bug.Y2K: When Computers Feared the Millennium BugThe Y2K bug was essentially the tech world‚Äôs version of forgetting to update your calendar. For decades, programmers had been using two digits to represent the year in their code (e.g., ‚Äú99‚Äù for 1999). But as 2000 approached, the fear was that computers would read ‚Äú00‚Äù as 1900, throwing modern society back into the days of horse-drawn carriages and telegrams.The world braced for impact. People joked about ATMs spitting out money like slot machines and traffic lights going disco on us. Governments and corporations spent billions to fix the issue. Midnight came, we all held our breath‚Ä¶ and then? Well, not much happened. It was like waiting for a sneeze that never came.Fast forward to today, and we can laugh about it. But guess what? We have another date with disaster in 2038, and this time, it‚Äôs a bit more specific: January 19, 2038, at 03:14:07 UTC, to be exact.Y2030 (or The 2038 Problem)Let‚Äôs talk about Unix time. Unix systems, which underpin much of the internet, count time in seconds from January 1, 1970 (known as the Unix epoch). The trouble is, they use a 32-bit integer to store this number. This was fine once it was introduced, but as we approach 2038, that number is going to max out.Imagine a 32-bit integer as a soda bottle. It‚Äôs been filling up, second by second, since 1970. In 2038, it‚Äôs going to overflow, and the clock will reset to something wacky, like December 13, 1901. Your smartphone might suddenly think it‚Äôs a pocket watch from the Victorian era.Let‚Äôs see why is that. Int32 type has 32 bits, out of which the first bit is used as a sign bit and the rest are used for value. If we take the current time we can get the binary representation:const date = new Date()// Tue Jul 16 2024 22:33:03 GMT+0200const binary = (+date/1000).toString(2) // divide by 1000, as Javascript counts milliseconds as well// 01100110 10010110 11011000 11111111Now imagine that we have all the ones for the value (1111‚Ä¶1111). Adding one more one would alternate the sign bit to 1, making this number the biggest negative integer that can be represented using the int32 type.\"1\"+\"0\".repeat(31)// 1 followed by 31 zeros-parseInt(\"1\"+\"0\".repeat(31), 2)*1000// parse that as integer and multiply by 1000 millisecondsnew Date(-parseInt(\"1\"+\"0\".repeat(31), 2)*1000)// Fri Dec 13 1901 21:45:52 GMT+0100 (Central European Standard Time)As you can see, it effectively brings us back to 1901, which can harm data in Unix-based systems.SolutionsUnsigned integersSome programming languages use unsigned integers for storing dates, which gives us an additional 2^32 seconds, or more practically speaking it overflows at 2106:new Date(parseInt(\"1\".repeat(32), 2)*1000)// Sun Feb 07 2106 07:28:15 GMT+0100 (Central European Standard Time)When it overflows, it goes back to 1970-01-01.Using 64bit numberGoing to 64-bit numbers will give us a much greater range, but usually what you‚Äôll see is that by using 64-bit Unix timestamp, is that it also takes milliseconds as well.Math.pow(2, 64)// 184467440737095520001000 /* milliseconds */ * 60 /* seconds */ * 60 /* minutes */ * 24 /* hours */ * 365 /* days */// 3153600000018446744073709552000 / 31536000000// 584942417.355072This gives us roughly 584 942 417 years since 1970 until overflow. That‚Äôs a lot.JavascriptHere things are a bit strange, as Javascript uses Double-precision floating-point format for representing numbers. On top of that, Date is limited to a range of exactly -100 000 000 days before and 100 000 000 after 1970-01-01 (in milliseconds).This gives us:100_000_000*1000*60*60*24=8640000000000000 milliseconds to work with in Javascript applications.new Date(8640000000000000)// Sat Sep 13 275760 02:00:00 GMT+0200 (Central European Summer Time)new Date(-8640000000000000)// Tue Apr 20 -271821 01:22:00 GMT+0122 (Central European Summer Time)new Date(8640000000000001)// Invalid Datenew Date(-8640000000000001)// Invalid DateWorry or not to worry?So, should we be worried? Maybe just a smidge. While the 2038 problem isn‚Äôt expected to be the global meltdown that Y2K was supposed to be, it‚Äôs still a significant issue. Systems that aren‚Äôt updated could fail, causing everything from minor inconveniences to major disruptions.On the bright side, programmers have had decades to learn from Y2K. If there‚Äôs one thing we‚Äôve learned, it‚Äôs to take these warnings seriously‚Ä¶ and to laugh a little along the way. Why did the Unix programmer go broke in 2038? Because their time was up!" }, { "title": "Typing systems explained", "url": "/posts/typing-systems-explained/", "categories": "javascript, typescript, java, go", "tags": "javascript, typescript, java, go", "date": "2024-07-02 20:45:00 +0200", "snippet": "In the realm of programming languages and type systems, understanding how types are enforced and interpreted is crucial for writing robust and maintainable code. Three common approaches to type checking are Duck Typing, Structural Typing, and Nominal Typing. Each has its own philosophy and use cases, influencing how programmers design and interact with code. This article explores these three typing systems, comparing their characteristics, advantages, and disadvantages.Nominal TypingDefinitionNominal Typing is based on explicit declarations and names. Two types are compatible if they have been declared to be so, usually by sharing a common ancestor or through explicit type declarations.Characteristics Name-based: Type compatibility is determined by explicit type names and declarations. Static: Typically used in statically typed languages. Explicit relationships: Types must be explicitly declared to be related.Advantages Safety: Ensures type safety through explicit declarations. Readability: Improves code readability and maintainability with clear type definitions. Tooling: Better support from IDEs and development tools for type checking and code completion.Disadvantages Verbosity: Requires more boilerplate code with explicit type declarations. Rigidity: Less flexible in terms of reusing code and adapting to changes.LanguagesJava and C# use nominal typing.interface Quacks { void quack();}class Duck implements Quacks { String name; public void quack() { System.out.println(\"Quack\"); }}class Person implements Quacks { String name; public void quack() { System.out.println(\"I'm quacking like a duck\"); }}public class Main { public static void main(String[] args) { Quacks d = new Duck(); Quacks p = new Person(); makeItQuack(d); // Outputs: Quack makeItQuack(p); // Outputs: I'm quacking like a duck } // it can accept Person or Duck because they both implement Quacks interface public static void makeItQuack(Quacks duck) { duck.quack(); } // on the other hand, this method cannot accept Person object, despite the // fact that shapes of the Person and Duck classes are the same public static String getDucksName(Duck duck) { return duck.name; }}Structural TypingDefinitionStructural Typing determines type compatibility and equivalence based on the structure (or shape) of the types, rather than their explicit declarations. If two types have the same shape, they are considered compatible.Characteristics Shape-based: Types are compatible if they have the required structure. Static or dynamic: Can be used in both statically and dynamically typed languages. Implicit compatibility: No need for explicit declarations of type relationships.Advantages Interoperability: Facilitates easy interaction between different types as long as they share the same structure. Flexibility: Supports code reuse and generic programming.Disadvantages Complexity: Type errors can sometimes be harder to trace due to implicit type relationships. Maintenance: Changes in type structure can have wide-reaching effects.LanguagesTypescript and Go use structural typing.class Duck { quack() { console.log(\"Quack\"); }}class Person { talk() { console.log(\"I speak English\"); } quack() { console.log(\"I'm quacking like a duck\"); }}function makeItQuack(duck: Duck) { duck.quack();}function makeItTalk(person: Person) { person.talk();}let d = new Duck();let p = new Person();makeItQuack(d); // Outputs: QuackmakeItQuack(p); // Outputs: I'm quacking like a duckmakeItTalk(p); // Outputs: I speak EnglishmakeItTalk(d); // Compilation errorDuck TypingDefinitionDuck Typing is a concept in dynamic typing where an object‚Äôs suitability is determined by the presence of certain methods and properties, rather than the object‚Äôs actual type. The name is derived from the saying: ‚ÄúIf it looks like a duck and quacks like a duck, it probably is a duck.‚ÄùCharacteristics Dynamic: Types are checked at runtime. Behavior-focused: If an object can perform the required actions, it is considered of the correct type. Flexible: Allows for more flexible and less verbose code.Advantages Ease of use: Reduces the need for explicit type declarations. Flexibility: Supports rapid prototyping and dynamic code changes. Less boilerplate: Minimizes the need for type annotations.Disadvantages Runtime errors: Type errors are caught at runtime, which can lead to unexpected failures. Lack of IDE support: Less assistance from development tools in terms of code completion and type checking. Reduced readability: Code can become harder to understand without explicit type information.LanguagesPython, Javascript and Ruby are prominent languages that use duck typing.class Duck { quack() { console.log(\"Quack\"); }}class Person { talk() { console.log(\"I speak English\"); } quack() { console.log(\"I'm quacking like a duck\"); }}function makeItQuack(duck) { // Here, we are not checking for the type of the object, // only if it has a method named 'quack' duck.quack();}function makeItTalk(person) { // Same here, which in our case will cause runtime errors person.talk();}let d = new Duck();let p = new Person();makeItQuack(d); // Outputs: QuackmakeItQuack(p); // Outputs: I'm quacking like a duckmakeItTalk(p); // Outputs: I speak EnglishmakeItTalk(d); // Runtime error: person.talk is not a functionConclusionUnderstanding the differences between Duck Typing, Structural Typing, and Nominal Typing is essential for choosing the right approach for a given project. Duck Typing offers flexibility and simplicity, making it ideal for dynamic environments and rapid prototyping. Structural Typing provides a balance of flexibility and safety, suitable for projects that require a middle ground. Nominal Typing ensures strong type safety and readability, ideal for large, complex systems that benefit from explicit type declarations and relationships.Each typing system has its own strengths and weaknesses, and the choice often depends on the specific requirements of the project and the preferences of the development team. By understanding these differences, developers can make informed decisions to leverage the right type system for their needs." }, { "title": "Rush Clock", "url": "/posts/rush-clock/", "categories": "javascript, typescript, react", "tags": "javascript, typescript, react, productivity", "date": "2024-04-27 00:05:00 +0200", "snippet": "Ever feel like time is slipping away faster than you can catch it?Say hello to the Rush Clock! üïí‚ö° It‚Äôs your go-to tool for managing time like a pro.Whether you‚Äôre tackling deadlines or simply want to make the most of every moment, the Rush Clock keeps you focused and motivated. Don‚Äôt let time control you ‚Äì take charge with the Rush Clock!Stay focused, stay motivated, and make the most of every second. Get yours now and embrace the power of efficiency!Click here to try it out!What does it do?If you didn‚Äôt figure out (or you simply missed) mystery clock on my last post, read along to discover how it works and what more can you do with it.It ticks faster at the beginning of the rush period and slower towards the end of the rush period.The default rush period is hourly, meaning it will start ticking faster at the beginning of the hour and slower towards the end of the hour.Other than hourly, there are daily and custom rush periods.Rush Clock AdminFeaturesRushness: Customize coefficient for how much you would like your clock to rush in front of real time.Alarm: Set alarms to stay on track with your schedule. Themes: Choose from different themes to personalize your Rush Clock experience. Digital Clock: Opt to display a real time digital clock alongside the Rush Clock, with customizable format options. Shadow Clock: Enable the shadow clock feature to reveal a real-time clock when clicking on the center of Rush Clock.SimulatorExperience Rush Clock's functionality firsthandwith the simulator feature. Compare real time analog clock with theRush Clock using the interactive slider.With Rush Clock, timekeeping becomes an engaging and dynamicexperience, offering both utility and aesthetic appeal.#Javascript #Typescript #React #Clock #Rush #Alarm #Productivity #Tools #Utility #RushClock #TimeManagement #Productivity #Efficiency #StayFocused #SeizeTheMoment #TimeIsPrecious #MakeEverySecondCount #Deadline #WorkSmart #BeatTheClock #ProductivityTools #StayOnTrack #TimeIsMoney #GetThingsDone" }, { "title": "This is NOT an ordinary clock", "url": "/posts/this-is-not-an-ordinary-clock/", "categories": "puzzle", "tags": "puzzle", "date": "2024-04-24 18:58:00 +0200", "snippet": "If you figure out how it works, leave a comment.Hint: try clicking somewhere on the clock." }, { "title": "Callback Scheduling in JavaScript: Fire Callbacks at the Stroke of Every Second", "url": "/posts/callback-scheduling-in-javascript-fire-callbacks-at-the-stroke-of-every-second/", "categories": "javascript", "tags": "javascript", "date": "2024-03-22 20:41:00 +0100", "snippet": "Sometimes you would like to execute a callback exactly on the stroke of each second. There are many cases when you would like to achieve such behavior, here are just a few examples: New Year‚Äôs Countdown Birthday Countdown Precise alarm clock Automating HTTP requests Precise animation triggersYou may think it‚Äôs not a big deal if you miss the exact stroke of a second, but it would be really nice to achieve precision when it comes to triggering animation at the exact time (like New Year‚Äôs Countdown).Logging timeFirst, let‚Äôs define our simple callback function logTime for testing:const logTime = () =&gt; console.log(+new Date());Converting Date to number will give us time since January 1. 1970 UTC, including milliseconds.That is important, as we‚Äôll see how much deviation we get from the stroke of a second.First attempt: setIntervalWhenever you need to achieve some periodic execution in Javascript, what first comes to mind is the setInterval Web API.In short, the setInterval function takes a callback as the first parameter and delay as the second.setInterval(logTime, 1000);This will schedule the execution of the logTime function each second, but the first execution will not have to be invocated at the stroke of a second (and it‚Äôs a rare chance it is). Here is the result of the setInterval call:1711139891173171113989217317111398931731711139894173Fixing the first invocationYou don‚Äôt want to start interval on some arbitrary point in time, but rather on the stroke of a second.So, essentially what you want to do is to delay setting up an interval until the next stroke of the second.What is used for delaying invocations in Javascript? That‚Äôs right, the setTimeout Web API.And how much time would you need to delay?That should be easy: as much time as we‚Äôre left with until the next stroke of the second.We can get milliseconds of the current time using:new Date().getMilliseconds()Since there are 1000 milliseconds in the second, we need to subtract current milliseconds from 1000 to get to the next stroke of a second.Let‚Äôs try it out.Similar to setInterval, the setTimeout will take the callback as the first parameter and delay as the second.setTimeout(logTime, 1000 - new Date().getMilliseconds());The result is probably what you expected, the method was executed at the stroke of the second:1711144065000Tying up the first invocation with intervalNow that we fixed the first invocation, it should be straightforward to tie it up with an interval:setTimeout( () =&gt; setInterval(logTime, 1000), 1000 - new Date().getMilliseconds());Finally, we got an interval that is executing a callback on each stroke of a second:1711144386000171114438700017111443880001711144389000Drifting awayJavascript setInterval and setTimeout Web APIs don‚Äôt guarantee that a callback will be executed at exactly the requested time.Furthermore, setInterval is susceptible to drifting away, especially if run for a long time.In order to fix this, we need to re-synchronize time intervals, which should keep us safe from drifting away phenomena.Fixing drift-away phenomenaInstead of using setInterval, we can use setTimeout in a recursive function. After every invocation, we‚Äôll calculate the next invocation time and schedule another execution using setTimeout:const clockTick = (callback) =&gt; setTimeout(() =&gt; { callback(); clockTick(callback); } ,1000 - new Date().getMilliseconds() );clockTick(logTime);This should give us a similar result as before, but with a stronger guarantee of the precise execution:1711146244000171114624500017111462460001711146247000Long execution timesIn general, you should avoid running expensive computations in callbacks that are scheduled. Depending on the desired behavior you can choose between two options: Block scheduling new execution until the current one is finished (this approach will skip over some invocations if they are not able to be scheduled on time) Allow multiple executions simultaneouslyOur solution that we implemented so far allows for multiple executions, given that callback is an async function.To convert it to block scheduling all we need to change is make the clockTick function async and await the callback to finish:const clockTick = (callback) =&gt; setTimeout(async () =&gt; { await callback(); clockTick(callback); } ,1000 - new Date().getMilliseconds() );" }, { "title": "IT Crossword", "url": "/posts/it-crossword/", "categories": "puzzle", "tags": "puzzle", "date": "2024-01-20 12:22:00 +0100", "snippet": "Try if you can complete this IT crossword. Good luck!Created with crosswordlabs.com" }, { "title": "Unlocking the Theater Experience", "url": "/posts/unlocking-the-theater-experience/", "categories": "reverse-engineering", "tags": "brute-force, bash, scripting", "date": "2024-01-12 21:48:00 +0100", "snippet": "New plays in local theaterRecently I stumbled upon an advertisement for the local theater. From time to time I like to bring my kids to a theater as they enjoy it. Wow, there is a play that I can bring my daughter to: ‚ÄúThe Snow Queen‚Äù!Entering mobile applicationSo I opened up the mobile application for a theater in order to buy tickets. My account expired some time ago and I needed to register again.And here comes the problem: I entered my phone number, but I didn‚Äôt receive the verification code by SMS.Registration over the mobile applicationThen, after 60 seconds I could try again, but still without success‚Ä¶Most likely their subscription plan expired and they didn‚Äôt check it in time.Trying over websiteI thought to myself ‚ÄúMaybe I got my account still logged in over their website. Let‚Äôs try it.Registration over websiteAh, no luck again!But wait, let me try entering some common number sequences:00001234999911119876No‚Ä¶ It was not a great idea anyway.PlanOk, so we can assume a few things here: verification code is a sequence of 4 digits (based on mobile application input) the sequence is generated once we ask for the verification code by SMS there is no limit to the number of retries for entering the verification codeThis sounds like a nice brute-forcing practice, isn‚Äôt it?What we have here is a classic ‚ÄúPermutations with Repetition‚Äù example. For more details, check this article: Combinations and PermutationsOk, so we got:Number of permutations = n^rn - number of possibilitiesr - number of appearancesIn our case: 10^4 = 10 000But it‚Äôs ten thousand combinations! It would take so much time to run it manually‚Ä¶..On the other hand, what if we used some script that would do this for us ü§îLet‚Äôs say that we run each combination once per 150ms, it would take us the maximum time of:10 000 * 150ms = 1 500 000ms = 1 500s = 25mWhy 150ms? Simply because we don‚Äôt want to make a bunch of requests to a server at once, to avoid rate-limiting or similar mechanisms. It‚Äôs still a risk with 150ms as well, but let‚Äôs hope it will work.CodeFor this purpose, I decided to use the bash script.Let‚Äôs do this step by step. If you‚Äôre eager to see the final result, you can jump to Running the application section.Iterate over all combinationsThe first step is to go over all possible combinations with delay. It should be quite easy:#!/bin/bashfor i in {0000..9999}; do echo \"Code: $i\" sleep 0.15doneIterate over all combinations with delayIntroduce UIInstead of having the application constantly printing out to a terminal, wouldn‚Äôt it be nicer to simply refresh the view itself? We‚Äôll go into details of setting up UI. If you want to skip this, you can jump straight to Preparing the curl section.Let‚Äôs define what UI we would like to have: title current code that is being tested a result of that test progress bar time elapsed#!/bin/bashDELAY=0.15printLayout() { echo echo \"Brute force attack\" echo echo \"Code:\" echo \"Result:\" echo echo '/ .................................................. (0%)' echo echo \"Time elapsed: 0 seconds\"}main() { printLayout for i in {0000..9999}; do # echo \"Code: $i\" sleep $DELAY done}mainCreate UIANSI Escape charactersAs we would like to move our cursor in different directions and change color in some places of UI, we need to use ANSI escape characters.To use them, we should use echo -ne, where n stands for not outputting trailing newline and e stands for enable interpretation of backslash escapesLet‚Äôs add some of them as variables for ease of use to the code:# ANSI escape codesESCAPE=\"\\x1B\"SAVE_CURSOR=\"$ESCAPE[s\"RESTORE_CURSOR=\"$ESCAPE[u\"BOLD=\"$ESCAPE[1m\"RED=\"$ESCAPE[31m\"GREEN=\"$ESCAPE[32m\"RESET_STYLE=\"$ESCAPE[0m\"MOVE_LINE_UP=\"$ESCAPE[1A\"...moveLinesUp() { local n=$1 local moves=\"\" for ((i = 0; i &lt; $n; i++)); do moves=\"$moves$MOVE_LINE_UP\" done echo $moves}UI Utility methodsIt would be nice to have two methods that would: create a string of repeating characters format elapsed seconds into a more readable format of seconds, minutes, hours, daysrepeatCharNTimes() { local n=$1 local str=$2 local result=\"\" for ((i = 0; i &lt; $n; i++)); do result=\"$result$str\" done echo \"$result\"}formatTimeElapsed() { local seconds=$1 local minutes=$((seconds / 60)) local hours=$((minutes / 60)) local days=$((hours / 24)) if ((days &gt; 0)); then echo \"$days days, $((hours % 24)) hours, $((minutes % 60)) minutes, $((seconds % 60)) seconds\" elif ((hours &gt; 0)); then echo \"$hours hours, $((minutes % 60)) minutes, $((seconds % 60)) seconds\" elif ((minutes &gt; 0)); then echo \"$minutes minutes, $((seconds % 60)) seconds\" else echo \"$seconds seconds\" fi}Animate Code lineLet‚Äôs start with the easy one: animating the line where we display the current code that is being tested:echo -en \"$SAVE_CURSOR $(moveLinesUp 6) \\rCode: \\t\\t$BOLD$GREEN$i $RESET_STYLE $RESTORE_CURSOR\"Notes: SAVE_CURSOR and RESTORE_CURSOR are useful to bring the cursor to where it was before we started this change \\r is used to go back to the beginning of the lineAnd we get something like this:Animating Code lineAnimating progress barIt‚Äôs fairly easy to animate the progress bar. You simply calculate the percentage and use it to display the appropriate number of hash symbols and dots. Also, we include the percentage at the end of the progress bar:MAX=9999local percentage=$((10#$i * 100 / MAX))pounds=$(repeatCharNTimes $percentage/2 '#')dots=$(repeatCharNTimes $((50 - percentage / 2)) '.')echo -en \"$SAVE_CURSOR $(moveLinesUp 3) \\r / $pounds$dots ($percentage%) $RESET_STYLE $RESTORE_CURSOR\"Add spinnerThe Spinner is a nice touch on the progress bar. It‚Äôs fairly easy to add it, but it does involve some tricks.What makes up the spinner is a sequence of characters:# Spinnersp='/-\\|'In our for loop, characters are wrapped around on each iteration with this nice trick:# Move spinnersp=${sp#?}${sp%???}What this line does is that it makes a new string out of two parts: ${sp#?} - this will expand string sp and drop a single character from the beginning (# followed by single ?) ${sp%???} - this will expand string sp and drop three characters from the end (% followed by three ?)We get the spinner with the utility method:getSpinner() { local spinner=$(printf '\\b%.1s' \"$sp\") echo $spinner}Which is simply getting the first character of the string spAnd finally, we can adjust our code to show the progress bar with the spinner at the beginning:spinner=$(getSpinner)echo -en \"$SAVE_CURSOR $(moveLinesUp 3) \\r $spinner $pounds$dots ($percentage%) $RESET_STYLE $RESTORE_CURSOR\"Animate Time elapsedThe last thing on UI changes is to animate Time elapsed, which is straightforward:start=$(date +%s)...main() { printLayout for i in {0000..9999}; do ... now=$(date +%s) elapsed=$((now - start)) formattedTimeElapsed=$(formatTimeElapsed $elapsed) echo -en \"$SAVE_CURSOR $(moveLinesUp 1) \\rTime elapsed: $formattedTimeElapsed $RESET_STYLE $RESTORE_CURSOR\"UI is finally ready!Here is what it looks like after all the changes:Expand with the progress bar and time elapsedHere is the complete code:Preparing the curlAfter some examination of the website, I noticed that the code is sent as a POST request together with the cookie and a token for successful validation.In short, curl is in the following form:curl 'https://pgpozoriste.me/phone/verify' -H \"cookie: &lt;cookie&gt;\" --data-raw \"_token=&lt;token&gt;&amp;code=&lt;code&gt;\"In our code right above the line now=$(date +%s), we can make the HTTP request using curl: request=$(curl 'https://pgpozoriste.me/phone/verify' \\ -H \"cookie: $cookie\" \\ --data-raw \"_token=$token&amp;code=$i\")This request will need to go to a redirect, so we need to instruct the curl to do it for us by setting the flag --location.Also, we don‚Äôt want to pollute the terminal with the curl statuses, so we‚Äôll include --silent option as well.The final request looks like this: request=$(curl 'https://pgpozoriste.me/phone/verify' \\ -H \"cookie: $cookie\" \\ --data-raw \"_token=$token&amp;code=$i\" \\ --location --silent)As you can see, it requires the cookie and token to be set, which we can write at the beginning of our script in variables of the same name.Then, after the request, we can inspect for its content like this: result=$(echo $request | grep \"Uneseni kod je pogre≈°an\" | wc -l) if ((result == 1)); then echo -en \"$SAVE_CURSOR $(moveLinesUp 4) \\rResult: \\t\\t$BOLD$RED Uneseni kod je pogre≈°an $RESET_STYLE $RESTORE_CURSOR\" else echo $request break fiFinal codeThe final code looks something like this:Tuning up the DELAY parameterAs it turns out, 150ms was way too quick and I quickly got Too Many Requests error.Trying out different values, I figured that for me it‚Äôs safe to use DELAY=5, meaning that the maximum time for checking all combinations is 10000*5s=50000s, or around 14 hours üòïStop and continueWhat is great is that you can always stop the script and just change for loop to start from the last checked sequence of digits. Just be careful if you stop it yourself to restart with the one combination before, as the terminal is showing the current Code being processed and not the previous.Running the applicationHere is the application in progress:Brute force in actionAfter some time, we finally got a success:SuccessThe last catch before entering the websiteThe mistake I made right away after getting the verification code was that I tried to enter it again. But refreshing the page actually triggered another verification code generation!Oh, time wasted on that‚Ä¶..Inspecting the website a bit more I discovered that the website is holding a cookie.Hm, ok then. So, if our code verification request is successful, does it mean that we can simply go to the home page and the cookie will make sure that we are logged in?In other words, maybe there is no need to enter the verification code, as we just did it by the curl?Let‚Äôs try that. And‚Ä¶ Yes! We are logged in, we just needed to go to the home page right away!Before code verificationAfter code verificationComparing these two, you can clearly see that instead of Prijavi se (Log in), now it has Moje ulaznice (My tickets) in the top right corner. By the way, cookie I found is set to expire at 2025-02-13T12:47:57.084Z, meaning we should be logged in for more than a year on this browser üßêSeats are bought!At last, I could go to a page for buying seats and although the first row was sold out, I found some nice seats in the second row (blue ones on the screen):Bought seatsTickets are in place and we‚Äôre set to go to a child‚Äôs play in two weeks üé≠P.S. But hey Borko, what about the mobile app?I‚Äôm glad you asked üòéAfter I finished with the website, I tried to open the mobile application to use the same code.But, it turns out that once you open the application, it asks for your phone number and then resets the verification code üòÆOk, here we go again‚Ä¶In short, I did the following: started mobile application, entered the phone number to get on the screen for entering code keep the application open in the background generate code via script as discussed before use that generated code to register a mobile applicationAnd voila, it works!Now I can have my tickets at the reach of my hand anytime üòåMobile app registered" }, { "title": "Modulo vs Remainder", "url": "/posts/modulo-vs-remainder/", "categories": "algorithms", "tags": "algorithms, modulo, remainder", "date": "2023-02-12 22:48:00 +0100", "snippet": "Once I had to migrate an application from Python to Javascript. Even though the code was copied almost exactly, tests were failing. After some time I finally found out that the % operator is not the same in Javascript and Python. It‚Äôs the Modulo operator for Python, but the Remainder for Javascript. Luckily, the fix is rather easy, you can find it at the end of this post.Quick refresh on % operatorMost tutorials for beginners in programming at some point teach to use the operator % to get the remainder after dividing one number by the other.Examples:7 % 5 = 24 % 2 = 0And you can verify it quickly: divide 7 by 5 7 / 5 = 1.4 round the result (in this case to 1) and multiply by the divisor (5) 1 * 5 = 5 7 - 5 = 2With the % operator, you can check for any positive integer if it‚Äôs divisible by another positive integer.This is handy in checking if the number is odd/even (by checking if it‚Äôs divisible by 2):const isEven = number % 2 === 0Why should I care?The % is usually applied to positive integers. But the difference appears when considering negative values.Let‚Äôs see them in action.Javascript uses % as the Remainder operator:console.log(7 % 5);// output: 2console.log(-7 % 5);// output: -2console.log(7 % -5);// output: 2console.log(-7 % -5);// output: -2Python uses % as the Modulo operator:print(7 % 5)# output: 2print(-7 % 5)# output: 3print(7 % -5)# output: -3print(-7 % -5)# output: -2DefinitionsFor the operationn % dwhere: n - dividend d - divisorModulo/Remainder is calculated with the formula:n - d * q Remainder uses the truncate of the result of the n / d to get quotient q Modulo uses the floor of the result of the n / d to get quotient qWhen both operands are of the same sign, floor and truncate will produce the same result, otherwise, they can differ by at most 1:floor(-1.5) = -2truncate(-1.5) = -1 There are other ways to calculate the quotient, but truncated and floored are the most used ones. For a complete list and to check what your programming language uses, check this Wiki page.Calculation-7 % 5 the modulo is calculated as:-7 - (5 * (floor(-7/5)))=-7 -(5*(-2))=-7 + 10 =3 the remainder is calculated as-7 - 5 * (truncate(-7/5)) = -7 -(5*(-1)) = -7 + 5 = -2Example of RemainderThe remainder is useful to check if a number is divisible by another number.Let‚Äôs say that you have a list that represents days in a week (Monday to Sunday), going from 0 to 6:[0 1 2 3 4 5 6]If the current day is Friday (4), how would you calculate what day would it be after 18 days?You could use either modulo or remainder like this:(4 + 18) % 7 = 1So, the result is Tuesday (2).Example of ModuloThat‚Äôs great, but what if you need to calculate what day it was 20 days ago?In this case, you could use the modulo to find out that:(4 - 20) mod 7 = 5And the result is Saturday (6).Intuition for remainder and moduloFor the non-negative numbers, you can see how the numbers wrap around the range 0 - 6:n0 1 2 3 4 5 6 7 8 9n % 70 1 2 3 4 5 6 0 1 2But if we include negative numbers, we‚Äôll get:n-9 -8 -7 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 7 8 9n rem 7-2 -1 -0 -6 -5 -4 -3 -2 -1 0 1 2 3 4 5 6 0 1 2n mod 75 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2For the negative values you can see that the remainder is producing the negative values that repeat once they reach the limit (remember d in n % d),Where modulo is repeating the same sequence we had in a positive spectrum ([0,1,2,3,4,5,6] in our case).Convert from Remainder to ModuloThe fix I mentioned at the beginning of the post is actually quite a simple one.Here is the function that will calculate the modulo of numbers a and b:function modulo(a, b) { return ((a % b) + b) % b;}" }, { "title": "Code review using Git", "url": "/posts/code-review-using-git/", "categories": "git", "tags": "git, code-review", "date": "2023-01-28 17:48:00 +0100", "snippet": "A common practice in modern software development companies is to have a Code Review process in their development teams, which I believe is a must for a clean code base.In this post, I am going to show you how I do the Code Review using Git.Simple vs complex PRsPRs can be divided into simple or complex. With practice, over time you can get a feeling of what makes a PR simple and what makes it complex, and it can differ from person to person. Anyway, each one of us considers some PR as simple or complex based on their criteria, or for the lack of it, just a gut feeling üòâ.Dealing with simple PRsFor simple PRs, I like to use the help of the platform where the code is hosted, be it GitLab, GitHub, BitBucket, Azure Repos, you name it. All of them are pretty good at offering basic functionality, such as: viewing the changed files making comments marking something as already reviewed offer suggestions the other developer can merge directly in their code (not all platforms, though)Dealing with the complex PRsNow, when it comes to complex PRs, what I am missing when using the above-mentioned platforms is to actually change the code itself, run the tests for my changes and commit these changes into a separate commit.Let‚Äôs formalize what is it exactly we want to achieve here: have the changes from the PR in Git‚Äôs Working Directory after reviewing the piece of code, commit original changes alongside changes from Code Review (if any) in the end, we‚Äôll have just one additional commit with Code Review changesPre-requisites Git VS Code (optional) Git Lens extension for VS Code (optional) All of the steps I will show can be made in any other IDE or even using the command line.My recipe for Code Review using Git revert all the commits from the PR starting from the latest reset to the last commit from the feature branch commit all changes from the Working directory to the ‚ÄúCode review‚Äù commit revert the ‚ÄúCode review‚Äù commit reset to commit ‚ÄúCode review‚Äù do the actual review and commit amend original changes with any modifications from the Code reviewDon‚Äôt worry if this looks too abstract, we‚Äôll cover it in the Example section.ExampleLet‚Äôs see how to use this flow on a sample project. You can clone this repo and try it out yourself hereProject setupTo keep things simple, I will use a project with two branches: main - the branch to which we are going to merge PR fix-prime - the branch on which changes are made and are ready for a reviewOn the main branch, we have two commits - the Initial commit with README.md and Prime where we added the prime.js file.main branchOn the other hand, the fix-prime branch has 3 commits in front of the main branch that are used to make fixes to the prime.jsfix-prime branchStep 1 - revert all the commits from the PRWe need to revert all the commits starting from the last commit made in the branch until we get to a commit from the main branch.step 1 - revert all the commits from the PRUsing git from the terminal you can do the same by running the following command for every commit:git revert --no-edit &lt;commit-SHA&gt;Step 2 - reset to the last commitOnce we have all the commits reverted, we‚Äôll reset to the last commit from the main branch.step 2 - reset to the last commit from the fix-prime branchgit reset &lt;commit-SHA&gt;Step 3 - create a new commit called ‚ÄúCode review‚ÄùNow we‚Äôll create a new commit with all changes in the Working directory and we‚Äôll name it the Code review.step 3 - create the ‚ÄúCode review‚Äù commitgit add .git commit -m \"Code review\"Step 4 - revert that new commitAfter we have all the reverted changes from commits in the feature branch merged into one commit (Code review branch), we need to revert that branch as well, and you‚Äôll see in a moment why.step 4 - revert the ‚ÄúCode review‚Äù commitgit revert --no-edit &lt;commit-SHA&gt;Step 5 - reset to commit ‚ÄúCode review‚ÄùNow reset to the Code review branch, essentially leaving changes of the commits from the feature branch to Git‚Äôs Working directory.step 5 - reset to the ‚ÄúCode review‚Äù commitgit reset &lt;commit-SHA&gt;Now that we prepared our code base for a code review, we can start the code review process.Step 6a - commit original changes as isNow we can go with the code review process. In this example, we‚Äôll show how to commit original changes without any modifications to them.step 6a - commit original changes to the ‚ÄúCode review‚Äù commitgit commit --amend --no-editStep 6b - commit original changes with some modifications from the code reviewYou‚Äôll see here how easy it is to make modifications to the original changes and commit them.We spotted that the condition is wrong, it should be &lt;= instead of &lt;. Let‚Äôs see how to do this modification.step 6b - commit modifications to the PR in the ‚ÄúCode review‚Äù commitgit commit --amend --no-editThe resultAnd this is what we get at the end - one commit with all modifications we made in the code review process.The result of the Code Review You may wonder what happens if you did not make any modifications? In such case, Git will warn you that doing commit amend will make your commit empty. It‚Äôs up to you do you prefer to have an empty Code review commit, or you prefer to delete it.If you choose to do the former, then you should commit with: git commit amend --no-edit --allow-empty" }, { "title": "Generics in Java part 3 of 3", "url": "/posts/generics-in-java-part-3-of-3/", "categories": "java", "tags": "java, generics", "date": "2022-10-16 18:07:00 +0200", "snippet": "This article is the third and final part of the series Generics in Java.Here are links to all parts: Generics in Java part 1 of 3 Generics in Java part 2 of 3 Generics in Java part 3 of 3Please check out parts 1 and 2 so you can follow along easily, as we cover the basic syntax and concepts such as type erasure and invariance.In this part, we are going to introduce bounded type parameters, generic methods and wildcards for generics.Bounded type parametersWe‚Äôve seen the power of Generics when it comes to making some class/interface generic without losing type safety. Now as great as it is, there still might be a place for improvement.Let‚Äôs say you want to restrict users of your Generic class to certain types (that have something in common). For example, what if you want to use subtypes of the List interface as your type parameter? Explicit type casting is one solution, but then we lose type safety.We know that classes and interfaces can be subtyped using inheritance. Generics offers you a similar mechanism to restrict type parameters in such a way that the type argument must be either the same class or its subtype.Such parameters are called Bounded type parameters.Here is an example:class GenericsClass &lt;T extends SomeBaseType&gt;Now, the type argument can be either SomeBaseType or any of its subtypes (interface or class).One classical example of this usage is using a Java Collections Framework:class GenericsExample &lt;T extends List&gt;This class could be instantiated in the following ways:GenericsExample&lt;List&gt; listExample = new GenericsExample&lt;&gt;();GenericsExample&lt;ArrayList&gt; arrayListExample = new GenericsExample&lt;&gt;();GenericsExample&lt;LinkedList&gt; linkedListExample = new GenericsExample&lt;&gt;();When we try to use the type that is not of the bounded type or its subtype, we get a compilation error:GenericsExample&lt;Collection&gt; collectionExample = new GenericsExample&lt;&gt;();Is there any other benefit to this bounded type parameter? Yes, as now the generic class can make sure that certain methods that come from bounded type are now available. In this example, since we know that type T is a List or its subtype, we can be sure that it must implement methods of the List interface.In other words, our Generic class can access methods that are defined by the bounded type.Therefore, we can do something like this:class GenericsExample &lt;T extends List&gt; { private T something; public Integer getSizeOfSomething() { return something.size(); }}If you remember Type Erasure, we said that the type arguments are replaced by the Object class. Well, in the case of a bounded type parameter, the type argument is replaced by the bound itself. This happens due to inheritance being covariant in Java. Check out part 2 of this series for more information.In the last example, it would be List. Of course, if we extended the class with the List&lt;Integer&gt; for example, it would still be the List, since there are no generic types in runtime (but at the compile time, Java will make sure you cannot put the item of the String type into the List&lt;Integer). Keep in mind that even at the bounded type parameters you should prefer the usage of full generic type instead of Raw Type.After compilation, our GenericsExample class would look something like this:class GenericsExample { private List something; public Integer getSizeOfSomething() { return something.size(); }}If you have multiple type parameters, you can make bounds on the previously set type parameter. For example, we can extend the second type parameter with the first type parameter: class GenericsExample &lt;T1 extends List&lt;String&gt;, T2 extends T1&gt;And both of them will be replaced with List after type erasure in the compilation.Valid bound typesHere is the list of the valid bound types: Class Interface Enum Parameterized type We can only use the extends keyword with bounds for type parameters, there is no implements keyword in this context.It should be clear by now how to use class, interface and enum as bounds. We already have shown an example of List&lt;String&gt; bound. But what if we don‚Äôt want to hardcode the type argument for this bound? We can use parameterized type bound:&lt;T extends Comparable&lt;T&gt;&gt;In this example, we can instantiate a class with any type T that implements a Comparable interface of the same type T.For example:class GenericsExample&lt;T extends Comparable&lt;T&gt;&gt; {...}GenericsExample&lt;Integer&gt; genericsExample = new GenericsExample&lt;&gt;();And that is because the Integer class indeed has in its signature: implements Comparable&lt;Integer&gt; (effectively allowing the Integer type to be referred to with the Comparable type).Multiple bound type parametersWe can make bounded type parameters with not just one, but multiple types. Let‚Äôs check an example:class GenericsExample &lt;T extends List &amp; Closeable&gt; {}In this example, we can see that GenericsExample is bounded by both List and Closeable interfaces.The type argument must be a subtype of all bounds, not just one of them. In other words, it‚Äôs a product algebraic data type.Example:class GenericsDemo &lt;T extends List &amp; Serializable&gt; {}Valid:GenericsDemo&lt;ArrayList&gt; test = new GenericsDemo&lt;&gt;();Invalid:GenericsDemo&lt;List&gt; test = new GenericsDemo&lt;&gt;();There are some rules to multiple bounds on type parameters: If a class is one of the bounds, it must be specified first There can be just one class in the bounds For final classes and enums - the type argument is bound itself (because the final class does not have a subclass and the enum is essentially a final class)Invalid bound types primitive arraysThese should not be a surprise. Primitive cannot be used anywhere in Generic anyway, and the array is a covariant type transformation, which clashes with Generic which is an invariant type transformation. Thus, it is forbidden to use an array as a bounded type parameter to keep invariance property and make code much more type-safe (for variance check out part 2 of the series).Generic MethodsJava Generics allows you to have Generic methods in your classes. This is especially useful for static utility methods, as we‚Äôll see later.The syntax for the Generic methods is the following:&lt;T1, T2, ...&gt; returnType methodName(T1 p1, T2 p2){}Here, &lt;T1, T2, ...&gt; must be placed between the return type and modifiers, for example:private &lt;T1, T2&gt; void genericMethod(T1 p1, T2 p2){}public static &lt;T1, T2&gt; void staticGenericMethod(T1 p1, T2 p2){} It‚Äôs not required for the class to be Generic to have Generic methods in it. This also stands true for Generic constructors.You can find a lot of Generic methods in the Java Collections framework. Let‚Äôs now take a look at a few examples:&lt;T&gt; T[] toArray(T[] a); // Java.util.Collectionpublic static &lt;T&gt; boolean replaceAll(List&lt;T&gt; list, T oldVal, T newVal) {...} // Java.util.CollectionsGeneric method - type scopeThe type parameters of the Generic methods are completely independent of the class-level type parameters.class GenericsDemo&lt;T&gt; { &lt;T&gt; void go(T object){}}It‚Äôs important to notice here that class-level parameter T is not the same as the method-level parameter T. When this method is used, it will take method-level parameter T instead of class-level one. The compiler would probably give you a warning like: ‚ÄúType parameter ‚ÄòT‚Äô hides type parameter ‚ÄòT‚Äô‚ÄùSo, it‚Äôs a good idea to avoid using the same type parameter name on the class level and generic method level.On the other hand, we can use both class-level and method-level type parameters in one method:class GenericsDemo&lt;E&gt; { &lt;T&gt; void go(T obj1, E obj2){}}As you probably guess already, such a method can‚Äôt be static, since we know we cannot use class-level type parameters in a static context.Bounded type parameters in generic methodsWe can also use bounded type parameters:&lt;T extends List &amp; Serializable&gt; void go(T object){}Everything we discussed so far about the bounded type parameters stands true for method-level type parameters.You can also have the method-level type parameter that extends the class-level type parameter like this:class GenericsDemo&lt;E&gt; { &lt;T extends E&gt; void go(T object){}}In the following example, we have the type parameter that extends the first type parameter:&lt;T1, T2 extends T1&gt; void go(T1 obj1, T2, obj2){}Method InvocationWe can either explicitly specify the type argument, or let the compiler infer the type from the method invocation.&lt;T&gt; T go(T object) { return object;}Double val1 = go(1.0);String val2 = go(\"String\");In this example type argument for val1 is inferred from the method itself and is of Double type (primitive type such as double is boxed into reference type Double).For the val2 type, the argument is String.Type argument inference is used not only here, but in diamond notation, as we already have seen in previous chapters.If the type parameter for the Generic method appears only in the return type of the method, then it is inferred from the calling context:&lt;T&gt; List&lt;T&gt; emptyList();(this method is from the Collections class)List&lt;String&gt; list = Collections.emptyList();In this example, calling context is helping out Java to determine the type argument for the method emptyList(), which is a String. On the left-hand side (List&lt;String&gt;) is what is called a target type and the compiler is going to pick it as a type argument.Notice that even if the target type is Collection&lt;String&gt; compiler is smart enough to understand that List is a subtype of a Collection, so it will infer the type argument successfully.Target type infernal works only if there are no parameter types in a method. In other words, Java will first try to figure out the type argument from the method parameters before looking at the return type. For example:&lt;T&gt; T go(T object) { return object;}Double val = go(\"java\");The type argument inferred here is String and it will throw the compilation error.Inferral will get the most specific common super-type.Example:&lt;T&gt; T go(T object, T object2) { return object;}var s = go(\"d\", new ArrayList&lt;String&gt;());In this case, both arguments are Serializable and that is what is inferred as the type argument for the variable s in this case.In some rare cases, there can be a need for explicitly setting type arguments.class GenericsDemo { &lt;T&gt; T go(T object) { return object; } GenericsDemo gd = new GenericsDemo(); var result = gd.&lt;Number&gt;go(1);}In this example, without using .&lt;Number&gt;, the variable result would be of the Integer type. Formally, this type argument is called Type witness.If the method is called within the same class, it should be called using this keyword: this.&lt;Number&gt;go(1);For static methods it should be called with a class reference, even if a method is called in the same class:GenericsDemo.&lt;Number&gt;go(1);WildcardsLet‚Äôs refresh the terminology once more: The Generic type is a type with type parameters (definition of classes/interfaces) The Parameterized type on the other hand is the one that we get once we change type parameters with actual types, in other words, type argumentsUp to this point, all we had for parameterized type is the concrete type.We have seen how we can make type parameters flexible by using bounded type parameters. This can be done in the definition of generic types (interfaces and classes), as well as generic methods.Is there some way to make parameterized types more flexible?Yes! Using something called wildcards for type arguments.Unbounded wildcardsWe know that a Generic type through its type parameter indicates that it can be instantiated with some desired type.For example:class Store&lt;T&gt; {}void foo(Store&lt;String&gt; stringStore) {}void bar(Store&lt;Integer&gt; intStore) {}But a parameterized type, like a Generic type, can also indicate that its type argument can be of an unknown type. And that is done using the wildcard symbol - ?.Let‚Äôs explain this with an example. If you have a method that is expecting some List and it‚Äôs only going to use the methods of the List interface on its input parameter, then this method does not need to know about the type of elements that are present in a list. So, you could use Raw type:void methodThatTakesList(List input) {...}But we already said this should be avoided since we lose type safety throughout our code. The solution is the usage of the unbounded wildcard:void methodThatTakesList(List&lt;?&gt; input) {...}In this way, we don‚Äôt hard code the type of elements in the list, but still keep type safety when using wildcard - ? in the same way, as if we would use concrete type.void go(Store&lt;?&gt; someStore);This can be read as A Store of some type. Method go doesn‚Äôt know or doesn‚Äôt care which kind of store it uses here.This wildcard - ? is known as an unbounded wildcard.The key point here is to remember that the type parameter is part of the class definition and the type argument is the actual type we are substituting when using the Generic class/interface.So ? cannot appear in the class definition, only in its usage. In other words, the Wildcard can be used only as a type argument, it cannot be used as a type parameter.Let‚Äôs see why is that so:class Test&lt;?,?&gt; { private ? a;}This would not compile, as it‚Äôs ambiguous.The wildcard is often used as a type of method parameter, like in a method go. It can be used in assignments as well, but that is something that is not commonly seen.Unbounded wildcard vs ObjectWhat is the difference between Store&lt;Object&gt; and Store&lt;?&gt;?Because of invariance, to Store&lt;Object&gt; we can only assign Store&lt;Object&gt;:Store&lt;Object&gt; someStore = new Store&lt;Object&gt;();But with wildcard we can assign an instance of any type:Store&lt;?&gt; someStore = new Store&lt;String&gt;();Store&lt;?&gt; someStore = new Store&lt;Integer&gt;();Invocation of the class-level type methodsTake a look at the following example:int getCommonElementsCount(List&lt;?&gt; list1, List&lt;?&gt; list2) { int count = 0; for (Object element: list1) { if (list2.contains(element)){ count++; } } return count;}Restriction on unbounded wildcards is that it‚Äôs not possible to invoke methods that use class-level type parameters with any arguments except null.Let‚Äôs see that in action with the example of the method getCommonElementsCount we just showed.Invalidlist2.add(25);Validlist2.add(null);That is because we cannot make assumptions about the type of objects in the getCommonElementsCount method.Bounded wildcardsBounded wildcards are mostly used in libraries, to make API flexible. Still, it‚Äôs good to know how they work, as it can help you a lot if you stumble upon some library code while debugging, or if you need to make your Java library.We can refer to parameterized types that use wildcards simply as wildcards types.Motivation for bounded wildcardsGenerics are invariant, which gives us type safety. Because of that, it is very restrictive and sometimes we need more flexibility. For example, if we know that we wouldn‚Äôt change the list, but just consume items from a list:void display(List&lt;Animal&gt; items)Here we cannot pass List&lt;Cat&gt; or List&lt;Dog&gt; to this method due to the invariance of Generics.One idea to solve this issue is to make separate methods:void display(List&lt;Animal&gt; items)void display(List&lt;Cat&gt; items)void display(List&lt;Dog&gt; items)Not only this introduces the additional complexity of maintaining multiple methods that have the same purpose but is also illegal due to type erasure as we‚Äôve already seen.Using different method names with raw types is not recommended either as we‚Äôll lose type safety.Upper-bounded wildcardLet‚Äôs take a look at the example of the upper-bounded wildcard:void display(List&lt;? extends Animal&gt; items) {...}Now display method can be invoked with a List of Animal items, or any subtype of Animal.The second alternative is to use the Generic method with the Bounded Type Parameter:&lt;T extends Animal&gt; void display(List&lt;T&gt; items){...}You may ask when to use one or the other since both of these approaches are perfectly valid.The general rule of thumb is: if the type parameter is reused throughout the method as return type and parameter type, then we would go for the generic method if the type parameter is used only once, for example for a parameter type, we can use a wildcardLower-bounded wildcardLet‚Äôs take a look at this example (assume that Animal is not an abstract class):void aggregate(List&lt;Animal&gt; list) { list.add(new Animal()); list.add(new Cat()); list.add(new Dog());}aggregate(new ArrayList&lt;Animal&gt;());Due to invariance, we cannot use any type other than Animal as a type argument for the list parameter.So, we cannot do something like this (assume that LivingBeing is the super-type of the Animal type):aggregate(new ArrayList&lt;LivingBeing&gt;());aggregate(new ArrayList&lt;Object&gt;());Due to invariance, even super-type of the type argument cannot be passed in here. We know that the Object is the super-type for all reference types.Upper-bounded wildcard cannot help us here, because it will make sure that only that type and its subtypes are eligible for replacement. But we would like to allow super-type in this method parameter.That is why for this purpose language designers introduced a lower-bounded wildcard:void aggregate(List&lt;? super Animal&gt; list) {...}With this, we can now invoke the method with either that type or its super-types. In our case, that would be Object, LivingBeing and Animal.Can you see that the unbounded wildcard is the same as the lower-bounded wildcard with an Object as its bound?In other words, &lt;?&gt; is the same as &lt;? super Object&gt;.We already said that you cannot invoke methods that use class-level type parameters with any arguments except null when using upper-bounded wildcards.But with a lower-bounded wildcard, we can invoke methods of class-level type parameters only if the method is of a lower-bounded type or one of its super-types:List&lt;? super Animal&gt;void aggregate(List&lt;? super Animal&gt; list){ list.add(new Animal()); list.add(new Cat()); list.add(new Dog());}aggregate(new ArrayList&lt;Animal&gt;());aggregate(new ArrayList&lt;Object&gt;());In this example, add() method is defined on the lower-bounded wildcard, so we can use it and keep type safety here.Restrictions of wildcardsWildcard can only have a single upper or lower bound!This is illegal:&lt;? extends bound1 &amp; bound2&gt;When to use which wildcardIf parameterized type is used to produce data, use upper bound:&lt;? extends bound&gt;If parameterized type is used to consume data, use lower bound:&lt;? super bound&gt;If parameterized type is used to produce data and doesn‚Äôt care about the type argument then use the unbounded wildcard (the same as the upper bound wildcard with an Object as the bound):&lt;?&gt;To summarize: If the method is used to produce data, we would use the upper bound type parameter If the method is used to consume data, we would use the lower bound type parameter If parameterized type is used as both producer and consumer, then use exact matchWe cannot have upper-bound and lower-bound at the same type for the type parameter.It doesn‚Äôt make sense either to do it, since in one case you can use types‚Äô super-type and in the other sub-type. The intersection between class subtypes and supertypes is exactly that type!PECSThere is a mnemonic that you can use to remember this:PECS -&gt; Producer-&gt;extends, Consumer-&gt;superExamplesExamples from Java Collections framework:&lt;T&gt; boolean addAll(Collection &lt;? super T&gt; c, T... elements) // consuming elements, hence super&lt;T&gt; void copy(List&lt;? super T&gt; dest, List&lt;? extends T&gt; src) // src is producer, dest is consumerboolean disjoint(Collection&lt;?&gt; c1, Collection&lt;?&gt; c2) // we don't care about exact types of c1 and c2&lt;T&gt; boolean replaceAll(List&lt;T&gt; list, T oldVal, T newVal) // types of list, oldVal and newVal must be the sameaddAll is used to consume elements, that‚Äôs why it‚Äôs appropriate to use super here, as we want to be able to put the element of type T in a Collection of type T or its supertype:// Using Collection of IntegerCollection&lt;Integer&gt; intList = new ArrayList&lt;&gt;(List.of(1, 2, 3));addAll(intList, 4, 5, 6);// intList = [1, 2, 3, 4, 5, 6]// Using Collection of Number (Number is the super-type of Integer)Collection&lt;Number&gt; numberList = new ArrayList&lt;&gt;();addAll(numberList, 4, 5, 6);// numberList = [4, 5, 6]copy is a great example of having both the consumer and the producer in the same method as parameters. Let‚Äôs break this up, so we understand what is the desired behaviour of this method:We want to be able to add elements of type T or its sub-type to a list of T or its super-typeList&lt;Number&gt; dest = new ArrayList&lt;&gt;(List.of(0, 0 , 0));List&lt;Integer&gt; intSrc = new ArrayList&lt;&gt;(List.of(1, 2, 3));List&lt;Long&gt; longSrc = new ArrayList&lt;&gt;(List.of(4L, 5L, 6L));List&lt;Double&gt; doubleSrc = new ArrayList&lt;&gt;(List.of(7.0D, 8.0D, 9.0D));copy(dest, intSrc); // dest = [Integer 1, Integer 2, Integer 3]copy(dest, longSrc); // dest = [Long 4, Long 5, Long 6]copy(dest, doubleSrc); // dest = [Double 7.0, Double 8.0, Double 9.0]disjoint will simply try to check if two sets are disjoint. For two sets to be disjoint, they can be of different types, and we don‚Äôt care about concrete types of collections as we are going to compare values using the equals() method. But it‚Äôs useful to keep type safety, as it‚Äôs good practice (remember to avoid the use of the raw types).Following the earlier example, we can do:boolean setsAreDisjoint = disjoint(dest, intSrc);Finally, replaceAll is going to take a list and two values, so they all must be of the same type. Therefore, here we‚Äôre going to use the type parameter itself instead of the wildcard:replaceAll(intSrc, 1, 4);" }, { "title": "Generics in Java part 2 of 3", "url": "/posts/generics-in-java-part-2-of-3/", "categories": "java", "tags": "java, generics", "date": "2022-10-05 23:27:00 +0200", "snippet": "This article is the second part of the series Generics in Java.Here are links to all parts: Generics in Java part 1 of 3 Generics in Java part 2 of 3 Generics in Java part 3 of 3Now that you know some basic syntax for Generics, as well as the motivation behind it, we can continue our journey to further expand our knowledge of Generics.In this part, we are going to introduce the concept of type erasure, invariance, and restrictions of generics.Raw Generic TypesWe already mentioned that Generics is a purely compile-time feature of the Java programming language, meaning the Generic types do not exist in the runtime.To keep Java backward compatible with the old versions, Generics allow you the usage of so-called Raw types.Imagine that you were going to use a library that is written in Java 8, but your code is written in Java 4. We know that Generics appeared in Java 5, so you cannot use Generic types directly.In this case, you can use Generic types without type arguments and still be able to include that library. Raw type is a Generic type without type arguments.Let‚Äôs show this with an example.We know that the Collections framework has Generic types. One such example is the List interface, which takes E as a type parameter.You already know by now how to create List of Integer element type:List&lt;Integer&gt; list = new ArrayList&lt;&gt;();But you are not required to provide a type argument, you can just leave it empty like this:List list = new ArrayList();What happens here is that the Object type will be used as a type argument. If you have multiple type parameters for your Generic class, you cannot omit just one type argument. You must either provide all type arguments, or omit them all (use Raw Generic type).This brings us back to our first solution in making some class generic - by using the Object type in a class. Compile time type safety is lost by using Raw Generics. Needless to say, this approach should be avoided. Using raw types is dangerous!Exceptions to not using Raw¬†typesWe already said that Raw types should be avoided, but sometimes there are cases in which you don‚Äôt have a choice but to use them: class literals (there is no List&lt;String&gt;.class per se, because generic types do not exist in runtime, so we must use List.class instead) instanceof operator (same reason as for class literals)Type ErasureFinally, we are going to look at how generics really work under the hood. What does it mean that generics are only compile-time features and they do not exist in runtime?During compilation, the Java compiler validates types in our code to make sure we don‚Äôt use Generic types in the wrong way. This is the point where we would get a compilation error if we misuse types.After the type check step, all type arguments are erased. This leaves us with an Object as a type where we had type parameters, just as we would have in a case we used a Raw type.In our Tuple example, after the compilation the class would essentially behave like this:public class Tuple { private final Object firstMember; private final Object secondMember; public Tuple() { firstMember = null; secondMember = null; } public Tuple(final Object firstMember, final Object secondMember) { this.firstMember = firstMember; this.secondMember = secondMember; } public Object getFirstMember() { return firstMember; } public Object getSecondMember() { return secondMember; }}Now you may ask but if types are replaced by Object, what happens to all places in the code where we used this Generic type? Are we going to lose the information about the type argument that is used when this class was instantiated?Well, it turns out that the compiler will insert an explicit type cast in all places that were using our generics type, so it will behave like this:public static void firstConsumer() { Tuple tuple = generateStringDateTuple(); String stringValue = (String) tuple.firstMember; java.util.Date date = (java.util.Date) tuple.secondMember;}To summarize, the compiler feature Type Erasure is doing two things after compilation: erases all type parameters of generics, leaving Object as the type where type arguments were used inserts explicit casting in places where generic types were used In the final part of this series we will show that we can force Java compiler to use some type other than Object when doing type erasure by something called bounds.Invariance in Java GenericsThis section contains a bit of theory on the type systems, so feel free to skip it if you want. Here are the key takeaways from this section: Java Generics are invariant, meaning you cannot substitute supertype or subtype of the type argument. Java Arrays are covariant, thus allowing for some type casting errors to slip to runtime Because of these facts, it‚Äôs recommended to use Generics instead of Arrays in Java when dealing with collectionsIf you want to learn more details about invariance and covariance, just keep on reading üôÇ.A brief overview of VarianceLet‚Äôs now discuss an important topic of variance in Java. This will get more theoretical, but you will find it quite rewarding as it deepens your understanding of the nature of the Generics in Java.As you already know, a type system in Java supports subtyping. It allows us to substitute a type with any of its subtypes.But what happens if we have some type transformations, for example, arrays and generics? Do transformed types keep the same relations as their underlying types? Or do they somehow change that relation?That behavior is defined by the variance. Each type transformation can have different variance and we‚Äôll show an example soon. It‚Äôs important to note that not all programming languages have the same variance for the same type transformations, but the concept is the same accross all languages. To give an example, in the OCaml programming language the list type constructor is covariant, whereas in Java the List generic type constructor is invariant.Types of varianceLet‚Äôs say that we have a type A and it is a subtype of type B. Also, we‚Äôll denote subtype relation with a ‚â§ symbol.If f is a type transformation, we can say the following: f is covariant if A ‚â§ B implies that f(A) ‚â§ f(B) f is contravariant if A ‚â§ B implies that f(B) ‚â§ f(A) f is bivariant if both of these apply (i.e., if A ‚â§ B, implies that f(A) ‚â° f(B)) f is variant if f is covariant, contravariant or bivariant f is invariant or nonvariant if not variantWe‚Äôll cover just what is relevant to our understanding of the Generics since this topic is huge and would require a series of articles for itself.Java Array vs Java GenericIn Java, we have the following: Generics are invariant Arrays are covariantGenerics are invariantLet‚Äôs walk through an example to understand the implications of these statements.We‚Äôll take Animal and Dog types.Dog‚â§Animal - we read this: Dog is subtype of Animal.Since Generics are invariant, we know that: List&lt;Dog&gt; is not a subtype of a List&lt;Animal&gt; List&lt;Animal&gt; is not a subtype of a List&lt;Dog&gt;Let‚Äôs see what would happen if the Generics were not invariant:void go(ArrayList&lt;Animal&gt; animals) { animals.add(new Cat());}go (new ArrayList&lt;Dog&gt;());The ClassCast Exception would be thrown in runtime, because we cannot cast Cat to a Dog, as we could to Animal.However, for the same type argument, inheritance of generic types is allowed:ArrayList&lt;Dog&gt; ‚â§ List&lt;Dog&gt; - ArrayList&lt;Dog&gt; is a subtype of List&lt;Dog&gt;, meaning that ArrayList&lt;Dog&gt; can be substituted where List&lt;Dog&gt; is expected.If you think about it, it makes perfect sense. Generic types are transformed to Raw types after compilation and they should behave in the same way as non-Generic types, meaning they should be covariant as simple types are covariant.Since type parameters for Generics are invariant in Java, we can say that Generics have much stricter type safety than Arrays, which we‚Äôll see in a moment.Arrays are covariantOn the other hand, since Arrays are covariant:Dog[] ‚â§ Animal[] - an array of the Dog objects is a subtype of an array of the Animal objectsBecause of that, we can do:Animal[] animals = new Dog[1];The same example as earlier:void go(Animal[] animals) { animals.add(new Cat());}go (new Dog[1]);This will throw ArrayStoreException (if the wrong type of object is stored in an array) in runtime.If you wonder why Java Array is covariant, it‚Äôs a decision made by language designers to allow a different kind of polymorphism back in the days when there were no Generics. Due to the invariance property of the Generic and the covariance property of the Array in Java, it is strongly recommended to prefer List over Array in Java code.Restrictions of GenericsLet‚Äôs switch back to the practical aspect of Generics. Let‚Äôs have a look at some restrictions on Generics.Type argument cannot be a primitiveIt‚Äôs easy to understand why, once you understand how Type Erasure works. As we already showed, the Java compiler is doing Type Erasure during compilation, which means it replaces Generic Types with Object (or some of its subclasses, as we‚Äôll show in the next part of the series).Hence, primitive types could not be used as type arguments.Type parameters cannot be used in a static contextThe easiest way to understand this statement is to go through an example:public class Inventory&lt;T&gt; { private static T inventoryType;}This code will fail to compile. Let‚Äôs understand why is that. Say we would like to make 2 Inventory instances, one of Packet class and the other of Letter class:Inventory&lt;Packet&gt; packetInventory = new Inventory&lt;&gt;();Inventory&lt;Letter&gt; letterInventory = new Inventory&lt;&gt;();What should the static field of Inventory class be? Is it Packet or Letter?And what if we didn‚Äôt create an instance of Inventory class at all?Now it should be obvious that the type parameter T could not be resolved correctly in the case of the static field.For the same reason, type parameters cannot be used in static methods and static initializers.Method overloading with different type argumentsThis is impossible due to Type Erasure:public List&lt;String&gt; get();public List&lt;Integer&gt; get();After type erasure, we would effectively get:public List get();public List get();And it‚Äôs invalid to have two methods with exactly the same signatureMethod overloading with type parameter and Object typeThis is invalid due to type erasure, as methods would have exactly the same signature:class GenericsExample &lt;T&gt; { public T get(T t){ return t; } public Object get(Object t) { return t; }}You should be able by now to figure out why this won‚Äôt compile üôÇ.Method overloading with type parameter and concrete typeLastly, one tricky example.This class definition is valid since after type erasure we don‚Äôt have a clash of method signaturesclass GenericsExample &lt;T&gt; { public T get(T t){ return t; } public String get(String t) { return t; } public String getExtended(String t) { return t + \" extended\"; }}If you instantiate this class with an Integer type argument, everything will be fine. Java compiler will effectively produce two get methods with Object and String as a parameter and return type. Also, every call to the get method of the Object type is explicitly type-casted with the Integer class. There is a clear distinction between calls to those methods.But let‚Äôs take a look at the case when you instantiate this class with String type argument.Since type erasure will replace T with Object there is no method signatures collision as we‚Äôve seen before, as we‚Äôll have:public Object get(Object t){ return t;}public String get(String t) { return t;}And those method signatures are different.But if there is an invocation of the get method in your code, a compiler will try to do explicit casting and at that point, it realizes that both Object and String versions of the get method would be eligible for this code.So the compiler will give you a compilation error exactly in places where you use the get method as it is ambiguous.Nonetheless, as we said you can instantiate this class with the String type argument and use other methods that are not ambiguous at the compile time, such as getExtended in our example.To summarize: this class definition is valid instantiation with any type argument is valid, even if that type is seemingly causing method signature collision you can use all the methods from such Generic class, except for the one that causes method signature collision It is strongly recommended not to use such class definitions that causes compilation errors for certain type arguments only. At least you should provide distinct method names to mitigate the risk of falling into this kind of situations.Generics in Java part 1 of 3" }, { "title": "Generics in Java part 1 of 3", "url": "/posts/generics-in-java-part-1-of-3/", "categories": "java", "tags": "java, generics", "date": "2022-09-25 17:34:00 +0200", "snippet": "In this series of articles, we‚Äôll discuss Generics in Java.Here are links to all parts: Generics in Java part 1 of 3 Generics in Java part 2 of 3 Generics in Java part 3 of 3Generics in Java had been introduced since Java 5. We‚Äôll see how they contribute to code reusability by adding an extra layer of abstraction over reference types.In this part, we are going to introduce the motivation for generics, their common usage, and basic syntax.A brief overview of PolymorphismPolymorphism promotes generalization. This brief overview will help us later on in our journey of learning Generics.In Java (or any other OOP language for that matter) superclasses can be used as polymorphic types for method parameters (including constructors) and can be used as return types of methods.This allows us to pass subclass objects as arguments and return subclass objects from methods.class Vehicle { private Date dateOfManufacture; ...}class SportCar extends Vehicle {...}class Minivan extends Vehicle {...}class Demo { public Vehicle generateVehicle(Boolean isForFamily) { if (isForFamily) { return new Minivan(); } else { return new SportCar(); } } public Date getVehicleDateOfRegistration(Vehicle vehicle) { return vehicle.dateOfManufacture; }}Method generateVehicle can return any Vehicle object or subclass of the Vehicle such as SportCar or Minivan.And method getVehicleDateOfRegistration can be invoked with any Vehicle or its subclass object, as we don‚Äôt care what exact type it is to get its dateOfManufacture field.Interfaces provide even more generalization since they can be implemented by classes from completely different class hierarchies.interface Printable { void print();}class Animal implements Printable { @Override public void print() { System.out.println(\"I am object of Animal class\"); }}class Employee implements Printable { @Override public void print() { System.out.println(\"I am object of Employee class\"); }}class Demo { public Printable getPrintable(Boolean isHuman) { if (isHuman) { return new Employee(); } else { return new Animal(); } } public void printIfNotNull(Printable printable) { if (print != null) { printable.print(); } }}As you can see, these classes do not have much in common, but since they share the Printable interface, we can use objects of these classes as method arguments or return types where the Printable interface is expected.Motivation for GenericsProgramming languages naturally evolve over time and developers themselves are usually the ones who are asking for certain language features. And in most cases, these features are something that is useful for developers but is still missing in a programming language.The same is true for Generics. To better understand how developers came up with the idea of Generics, we can go through an example.Example introductionMethods in Java natively cannot return multiple values. So you decide to make your own class that will help you achieve this goal. So you create a very simple class StringIntegerTuple that just has a constructor and a getter for underlying fields:public class StringIntegerTuple { private final String text; private final Integer number; public StringIntegerTuple(final String text, final Integer number) { this.text = text; this.number = number; } public String getText() { return text; } public Integer getNumber() { return number; }}Now you can use this class as a return type of method. This allows you to return String and Integer to the calling method.public StringIntegerTuple calculateAndReturnResultWithComment() { Integer result = 10; String comment = \"Result is ten\"; return new StringIntegerTuple(comment, result);} In general, you could use subtypes instead of exact types String and Integer, but these classes are final, which means they cannot have subtypes. Still, for simplicity we chose String and Integer in this example.You like this approach and you start building similar classes: StringDoubleTuple StringFloatTuple IntegerIntegerTuple ‚Ä¶Now you notice that the code base starts to grow purely because our helper classes use hard-coded types, so you would like to generalize it somehow.Generalize Tuple without genericsAt this moment it‚Äôs obvious that you would like a way to generalize these classes.So you come up with a following idea: let‚Äôs use the superclass of all the classes, in other words, use Object class instead of both types for the tuple:public class Tuple { private final Object firstMember; private final Object secondMember; public Tuple(final Object firstMember, final Object secondMember) { this.firstMember = firstMember; this.secondMember = secondMember; } public Object getFirstMember() { return firstMember; } public Object getSecondMember() { return secondMember; }}And it would be used like this:public Tuple calculateAndReturnResultWithComment() { Integer result = 10; String comment = \"Result is 10\"; return new Tuple(comment, result);}Now you are happy that all those classes are gone. But wait for a second, we just introduced some problems here.The downside of generalization with Object classAs we are dealing with an Object class, to make use of it we need to do explicit casting. And that produces error-prone code since there is no type of safety anymore!Let‚Äôs say that some class method is returning Tuple with types String and Date (java.util.Date):public static Tuple generateStringDateTuple() { String stringValue = \"\"; java.util.Date date = new java.util.Date(); return new Tuple(stringValue, date);}Now consumers need to do the explicit cast of the return typespublic static void firstConsumer() { Tuple tuple = generateStringDateTuple(); String stringValue = (String) tuple.firstMember; java.util.Date date = (java.util.Date) tuple.secondMember;}public static void secondConsumer() { Tuple tuple = generateStringDateTuple(); String stringValue = (String) tuple.firstMember; // next line will throw the ClassCastException at runtime java.sql.Date date = (java.sql.Date) tuple.secondMember; }The second consumer will throw ClassCastException because it uses the wrong type and therefore secondMember cannot be successfully type casted.So, to summarize the downsides of this approach: loses type safety requires explicit casting introduces runtime errorsGenerics example Generics is purely a compile-time concept. There are no generics in runtime! We‚Äôll discuss this later on when we are talking about type erasure.Now that we‚Äôve seen the pre-generics generalization approach, we can switch to a Generics feature of Java to solve this design problem.For now, don‚Äôt worry about how exactly Generics works, we will cover it later on. But first, we will show an example and what benefits we get from this approach.With Generics in place, we can rewrite the class as follows:public class Tuple&lt;T, U&gt; { private final T firstMember; private final U secondMember; public Tuple() { firstMember = null; secondMember = null; } public Tuple(final T firstMember, final U secondMember) { this.firstMember = firstMember; this.secondMember = secondMember; } public T getFirstMember() { return firstMember; } public U getSecondMember() { return secondMember; }}The usage is now different. Our producer would look like this:public static Tuple&lt;String, java.util.Date&gt; generateStringDateTuple() { String stringValue = \"\"; java.util.Date date = new java.util.Date(); return new Tuple&lt;String, java.util.Date&gt;(stringValue, date); }Let‚Äôs take a look at the same example we did for a Tuple without Generics:public static void firstConsumer() { Tuple&lt;String, java.util.Date&gt; tuple = generateStringDateTuple(); String stringValue = tuple.firstMember; java.util.Date date = tuple.secondMember;}public static void secondConsumer() { Tuple&lt;String, java.util.Date&gt; tuple = generateStringDateTuple(); String stringValue = tuple.firstMember; // next line will throw a compilation error java.sql.Date date = tuple.secondMember;}This code will not compile, since there is type check at compile time and most probably your editor will give you a warning for 3rd line in the secondConsumer method even before you try compilation.Note how there is no more explicit casting for the type of object when using Generics.It‚Äôs very easy now to create Generics Tuple with different types for their fields:Tuple&lt;String, Double&gt; stringDoubleTuple = new Tuple&lt;String, Double&gt;();Tuple&lt;String, Float&gt; stringFloatTuple = new Tuple&lt;String, Float&gt;();Tuple&lt;Integer, Integer&gt; integerIntegerTuple = new Tuple&lt;Integer, Integer&gt;();Now, to summarize the upsides of this approach: type safety at compile time explicit casting is no longer required cleaner code code is generic (you can instantiate the same class with different type parameters)Java Collections FrameworkSome of the most used generics are the ones from Java Collections Framework.Prior to Java 5, Java Collections Framework used the Object as a polymorphic type. Even keys and values in maps were Object types. But since Java 5, Collections Framework switched to Generics.You are probably already using them, as they are the foundation of Data Structures in Java. Here is the list of the most used ones: Collection&lt;E&gt; List&lt;E&gt; Map&lt;K, V&gt; Set&lt;E&gt; Queue&lt;E&gt;Generics basic syntax and terminologyLet‚Äôs take a closer look at the basic syntax and terminology for the generics.Generic type A Generic type is a class or an interface with type parameters defined in the declarationclass ClassName &lt;T1, T2, T3, ...&gt; {...}Syntax of the generic type is simple, it‚Äôs the same as an ordinary class or an interface with something called type parameters. These are listed within &lt; and &gt;. In our example that would be T1, T2, T3‚Ä¶ You can use any identifier, it does not have to start with T, we could use something like &lt;X,Y,Z&gt;.The naming convention for type parameters is to use single uppercase letters (although it‚Äôs not mandatory for your code to work).In many cases type parameter points to its nature, for example: E for element K for key V for value (check Java Collections Framework)Now, these type parameters can be used in a class (or interface) to represent the type of: instance variables parameters local variables return typesIn our example of a Generic class, we can see that T and U are used as: type of the class fields for firstMember and secondMember type of the parameters for the constructor the return type of the gettersType ParameterNow that we‚Äôve seen how generic type is constructed, let‚Äôs look at how type parameters can be used when constructing instances of the generic classes.Back to our example:Tuple&lt;String, java.util.Date&gt; stringDateTuple = new Tuple&lt;String, java.util.Date&gt;();Tuple&lt;String, String&gt; stringStringTuple = new Tuple&lt;String, String&gt;();Tuple&lt;Integer, String&gt; integerStringTuple = new Tuple&lt;Integer, String&gt;();Tuple&lt;String, List&lt;String&gt;&gt; stringListTuple = new Tuple&lt;String, List&lt;String&gt;&gt;();In fact, we can make this even simpler, because Java can infer types of parameters on the right-hand side. This &lt;&gt; notation is called Diamond notation and can be used from Java 7 onwards.Tuple&lt;String, java.util.Date&gt; stringDateTuple = new Tuple&lt;&gt;();Tuple&lt;String, String&gt; stringStringTuple = new Tuple&lt;&gt;();Tuple&lt;Integer, String&gt; integerStringTuple = new Tuple&lt;&gt;();Tuple&lt;String, List&lt;String&gt;&gt; stringListTuple = new Tuple&lt;&gt;();Did you notice something interesting here? The type parameter itself can be another generic type üôÇ. In this case it‚Äôs List&lt;String&gt;There are two important distinctions in the terminology of Generics: Generic type is a type with type parameters, as we‚Äôve already seen Parameterized type on the other hand is the one that we get once we change type parameters with actual types, in other words type argumentsGenerics basic syntax summaryIt‚Äôs much clearer when you check out the example: Tuple&lt;T, U&gt; - generic type Tuple&lt;Integer, String&gt; - parameterized type T and U - type parameters Integer and String - type argumentsSubtyping Generic typeWe can subtype Generic type in a very similar way as we would do if we had regular classes and interfaces.Let‚Äôs start with an interface:interface Pair&lt;F, S&gt; { F getFirstMember(); S getSecondMember();}As you can see, it‚Äôs defining getters for first and second members and is generic. In other words, it doesn‚Äôt require any specific type, but instead, it defines methods that should exist and their return types are generic ones.Next, we can take the same Tuple class we are working with and change its definition:public class Tuple&lt;T, U&gt; implements Pair&lt;T, U&gt; { ...}Type parameters are intentionally different in definitions of interface and class, so we can show how they have a meaning only in the context they are used. You can think of them as placeholders for real types.What I want to say is that these type parameters F and S for interface Pair has a meaning in that interface definition only. In order to transfer type parameters from the Generic class that implements this interface, it‚Äôs important to use the same type parameters (in this case T and U).Subtyping the Generics in last example allows us to reference an instance of Tuple as an interface Pair:Pair&lt;String, java.util.Date&gt; stringDateTuple = new Tuple&lt;&gt;();And here is how we got ourselves polymorphism with generics ü§Ø Another term for Generics is Parametric Polymorphism" }, { "title": "SQL: NULL values in UNIQUE vs DISTINCT", "url": "/posts/sql-unique-vs-distinct/", "categories": "databases", "tags": "databases, sql", "date": "2022-08-30 20:10:00 +0200", "snippet": "There is a subtle difference in how SQL UNIQUE and DISTINCT reason about NULL values. For UNIQUE they are not the same, but for DISTINCT they are ü§ØCheat Sheet UNIQUE constraint makes sure no values will be the same in that column except for null values. DISTINCT on the column will return all possible values (including null) exactly once.UNIQUELet‚Äôs say you have a very simple table customer that has a primary key id that is also auto-increment, and two more columns: name and personal_id.Furthermore, you know that personal_id cannot be the same for any of the customers, so we‚Äôll put the UNIQUE constraint on this column.DDL for such a table (for Postgresql) would be like this:create table customer ( id Serial primary key, name varchar(50), personal_id varchar(50) unique);Now, let‚Äôs populate this table with some data:INSERT INTO customer(name, personal_id)VALUES('Darrel Beckett', '875820185015303160')('Franklyn Paget', null)('Russ Thompkins', '173662838850888606')('Jackson Martinson', '459054575053219773')('Yolanda Frost', null)('Lindsay Granger', '625931342427148797')('Corbin Steele', '916300003568751325')('Christen Hanson', null)We can notice there are multiple rows with null value for a personal_id.The reasoning behind this is as follows: With a UNIQUE constraint null values are interpreted as unknown, therefore not breaking the rule of the uniqueness of the column. In other words, a null is the abscence of the value rather than the value itself. It‚Äôs simply a placeholder for a possible value, which can be filled in later on.DISTINCTNow let‚Äôs try to get distinct values from personal_id column in our table:SELECT distinct personal_idfrom customer;What exactly Distinct is doing? As the name suggests, it returns distinct values, so any repeated value would be returned only once. Unlike for the UNIQUE constraint, from DISTINCT point of view, all null values are the same. The reasoning behind this is that there is at least one unknown value, rather than returning all unknown values.The result should not be surprising:personal_id(null)173662838850888606875820185015303160459054575053219773916300003568751325625931342427148797What you should take care of is how you interpret those results. number of values in UNIQUE column is not always the same as number of values returned by DISTINCT on the same column. It depends on null values, as we‚Äôve seen. If there is maximum one null value in the column, they are the same, otherwise they are not." }, { "title": "Floyd cycle detection", "url": "/posts/floyd-cycle-detection/", "categories": "algorithms", "tags": "algorithms, cycle detection", "date": "2022-08-21 10:10:00 +0200", "snippet": "TL;DRTo check for the existence of a cycle in Linked List, you can use Floyd cycle detection (tortoise and hare algorithm).I created a mini-game Tile walker üèÉ‚Äç‚ôÇÔ∏è that shows the use of Floyd cycle detection, you can check it out here.Linked list data structureLinked list is one of the simplest data structures. The idea behind it is to make related objects connect by holding a pointer or a reference to the next object in a collection.There are three main types of Linked List: Simple Linked List - each member contains information about the next member in the list (if it exists) with a next pointer/reference. The last element‚Äôs next pointer points to null. Doubly Linked List - same as Simple Linked List, with additional previous pointer/reference that points to a previous member of the list. The first element‚Äôs previous pointer points to null. Circular Linked List - same as Doubly Linked List, but previous pointer of the first element in the list points to the last element in the list, and the last element‚Äôs next pointer points to the first element in the list, effectively connecting the list into a loop.We are going to use a Simple Linked List for the problem we are going to present.Traversal of the Linked ListLet‚Äôs take an example of a simple Linked List of integers:Simple Linked ListTraversal is very simple. We start from the first member, take its value and go on to the next member following the pointer, until the pointer of the member points to null.In this way we are getting the following result:805, 248, 324, 123, 518Linked List cycle detectionLinked List is not always going exclusively forward. Sometimes you need to point to a member in a list that already exists.For example:Linked List with a cycleAs we can see in this example, this Linked List does not have an end member, as all members of the list point to some other member, and none of them points to null.While traversing the list, you will repeatedly walk over the same list members:Start processWait for inputVerify inputProcess inputNotify userWait for inputVerify input...In this example members from id 1 to id 4 are connected in a loop, or in other words, they are forming a cycle.Here one natural question arises: how can we detect the existence of a cycle in a Linked List?The problem is formally known as The cycle detection problem.Naive approachThe easiest solution that can be implemented is to save pointers to a list of members as we traverse the Linked List. In every iteration, we are checking if the pointer to that list member is already present in our set of pointers.Here is the naive approach for the example above: iteration current set state current id element was in set 1 [] 0 no 2 [0] 1 no 3 [0, 1] 2 no 4 [0, 1, 2] 3 no 5 [0, 1, 2, 3] 4 no 6 [0, 1, 2, 3, 4] 1 yes As we can see, we are expanding our set of pointers until we come across the pointer that is already present in the set, or we come across a null pointer, which means that list is cycle-free.Complexity analysisComplexity analysis is very simple for this algorithm:Time complexity is O(N), because we need to traverse all list members and this is the low as we can get, so this is already the greatest time complexity.Space complexity is O(N), because in the worst case we need to store all list elements in the set until we get to the end of the list that does not have cycle in itself.As we can see from the analysis, we can affect only space complexity.Floyd cycle detectionThe algorithm that was introduced by Robert Floyd is using 2 pointers with which Linked List is traversed in O(N) time, but since we are using exactly 2 pointers, space complexity is going to be constant, or O(1).Let‚Äôs see how it works.Both pointers start from the beginning of the list. The first pointer advances one step per iteration, whereas the second pointer advances two steps per iteration. If the faster pointer comes across a null pointer, it means that Linked List does not have a cycle in it. Otherwise, these two pointers will meet at some moment and they will point to the same list member, hence proving that there is a cycle.We can show how it works in an example from above: iteration first pointer second pointer 1 0 0 2 1 2 3 2 4 4 3 2 5 4 4 Here you can see the demo animation:Floyd cycle detection iterationsFinding the beginning of the cycleIf there is a cycle in a LinkedList, we can find out the start of the cycle in the following way: reset one pointer to the start of the Linked List advance both pointers at the same speed (1 list member per iteration) until they meet their meeting point is the start of the cycleThat explanation is probably counter-intuitive, so let‚Äôs try to explain what exactly happens here:Cycle start calculation For simplicity, the formula we are going to derive here works only for cases where X &lt;= C. Later we‚Äôll cover the general formula, you can check it hereLet‚Äôs express the distance traveled by both slow and fast pointers before they meet each other:slow_pointer_distance = X + Yfast_pointer_distance = (X + Y + Z) + Y = X + 2Y + ZWe know that the slow pointer is exactly 2 times slower than the fast pointer. So, when they meet, the fast pointer must travel 2 times greater distance:fast_pointer_distance = 2 X slow_pointer_distanceWith the given equations above, we get:X + 2Y + Z = 2 (X + Y)X + 2Y + Z = 2X + 2YX + Z = 2XX = ZIf we translate X and Z for what they really are, we get:distance from First node to Cycle start == distance from Pointer meeting point to Cycle startNow it should be clear that if we move one pointer to the first node and move pointers at the same speed (one step per iteration), they will meet at the Cycle start!Finding Cycle startCalculating length of the cycleOnce we know the starting point of the cycle, we can calculate its length in a very simple way.All we need to do is to: start with both pointers from the start of the cycle traverse with another pointer until we meet the fixed pointerSimple as that üòÉCycle lengthWhat if X &gt; CIn the example above we assumed that X &lt;= C. In case that X &gt; C, the formula would change a bit, since the fast pointer can make N number of cycle traversals until it finally meets the slow pointer, where N &gt; 1 (in general case N cannot be lower than 1 since faster pointer will go with 2X speed the slow pointer, so it will for sure make at least one round trip of the cycle if the cycle exists).The fast pointer would travel:X + N * C + YAnd the slow pointer is covering the distance of:X + YSince the fast pointer covers 2 times the distance of the slow pointer, we get the following equation:2 (X + Y) = X + N*C + Y2X + 2Y = X + N*C + YX + Y = N*CX = N*C - YRewrite N*C as (N - 1) C + C, and then (N - 1) C + (Y + Z)X = (N - 1) C + (Y + Z)- YAnd finally, we get the general formula for all cases:X = (N - 1) C + ZWe can notice that for N == 1, we get the same as before: X = ZBut what this really means is that distance X is the same as the number of cycles N-1 that fast pointer travels + distance Z. So when advancing one pointer from the start of the list, and another from their meeting point, the second one will travel N-1 cycles and then meet the first pointer at the start of the cycle.It doesn‚Äôt matter if you didn‚Äôt quite catch all of this, here is the demo that can help you out üôÇWhen X &gt; CWhen Cycle start node == Pointers Meeting pointThere is a case where the cycle start node is the same node as the pointers meeting point node.In such a case, we have:slow_pointer_distance = Xfast_pointer_distance = X + N*CSince fast pointer is covering 2X distance of slow pointer, we have:2*X = X + N*CX = N*CThis means that distance from the start of the list to the start of the cycle is exactly the distance fast pointer traveled around the cycle üòÉ!In other words, whenever X is an exact multiple of cycle length C, we know that the pointers meeting point and the cycle start nodes are the same node.When Meeting point is same as Cycle startTile Walker - mini gameHere is an educative mini-game Tile Walker that is using Floyd cycle detection to detect cycle in a Linked List in order to conclude that Tile Walker has exhausted all tiles it will walk over in a game.You can check out the game here.And code can be found here.RulesThe player is walking in the same direction until he comes across an obstacle. Then it will make a turn of 90 degrees and continue walking in that direction.The goal is to set up the board, so the Tile Walker can cover as many tiles as possible.Where Floyd cycle detection is used here?When a player starts the game, it will simulate how Tile Walker is going over the playfield. Once it‚Äôs not able to cover more tiles, the game stops. To detect when this happens, we use Floyd cycle detection, but with a twist, since we need to compare not just the location of the player, but its direction as well.For more info, please check out the repo here." }, { "title": "String pool in Java", "url": "/posts/string-pool-in-java/", "categories": "java", "tags": "string pool, java, string, performance, utf-16, ascii", "date": "2022-07-29 18:50:00 +0200", "snippet": "In this post you will learn about String constant pool (or String pool for short) in Java.Knowing about String pool will deepen your knowledge of Java internals, which is always a plus for a Software Developer.Let‚Äôs start with the basics.StringIn Java, the smallest unit of textual data is represented as char (character), which is UTF-16 encoded (more on character encoding here ).To create of collection of characters, we could use a character array like this:char[] someText = {'a', 'b', 'c', 'd'};But there is a simpler way to represent a sequence of characters in Java:String someText = \"abcd\"; \"abcd\" in code above is called String literal.In the example above, string someText represents a sequence of characters, but it‚Äôs not a primitive type. When you create a string in Java, you are creating an object of the String class.It‚Äôs a special class in Java that has additional features when compared to other classes: it‚Äôs immutable, meaning once created it cannot be changed (more on why is so later, check here) it‚Äôs the only class where operator overloading is supported in Java. We can concatenate strings using the + operator. For example \"a\"+\"b\"=\"ab\". it‚Äôs final by definition, so no other class can override the methods of the String class. This guarantees that the behavior of the String objects is the same everywhere.Not only does it give you a more concise representation of the characters collection, but it also has a lot of helper methods like startsWith, endsWith, compareTo, compareToIgnoreCase, replace, replaceAll‚Ä¶ Note on Compact Strings We already know that char is UTF-16 encoded, which means that it takes 2 bytes per character. But not all characters need 2 bytes (ASCII characters requires just 1 byte of memory). That is why starting from Java 9 there is a new representation of a String, called Compact String. Instead of char[], it will choose between char[] and byte[] depending on the content that is stored. This greatly reduces the size of the memory used for strings if they are predominantly made up of ASCII characters, and improves Garbage Collector performance.Comparing stringsLet‚Äôs take a look at the following code:String s1 = \"abcd\";String s2 = \"abcd\";boolean areStringsTheSame = s1 == s2;What do you expect to see as a value of areStringsTheSame variable? If you guessed true you would be right.And what about the following code:String s1 = new String(\"abcd\");String s2 = new String(\"abcd\");boolean areStringsTheSame = s1 == s2;Now, the value of areStringsTheSame is false!What is going on here ü§î? String comparison should be done with equals() or equalsIgnoreCase() methods, since they will compare the content itself, not the reference to the objects like == operator. We are doing it here to demonstrate how strings are internally stored by Java in memory.String poolLet‚Äôs take a look at what happens in the example of declaring a string.String s1 = \"abcd\";As for any other class, Java will create an object instance of the String class.Now, s1 is a reference to that object, and it‚Äôs placed on the stack (as is expected).String literal (value) on the other hand is put in a heap, but in a special place called String pool.The following diagram explains the memory allocation for the above declaration:graph LRs1 --&gt; V[''abcd'']subgraph Stacks1endclassDef subgraph_padding fill:none,stroke:nonesubgraph HeapV subgraph 1 [ ] subgraph SP[String pool] V end endendclass 1 subgraph_padding String pool is not local for the thread. Each string is available to all threads for our application.String InterningWhy is Java using String pool in the first place?It takes advantage of the immutability of strings to optimize memory allocation in a heap by storing only one instance of string literal for all appearances in the program.This process of maintaining String pool is called Interning.Each time a String variable is created and assigned with string literal, Java compiler will search the String pool for a string with equal value. If found, it will be reused by passing a reference to this object instance in String pool. Otherwise, it will be created just as we described earlier. In this way, memory allocation is reduced.Let‚Äôs expand on the example with the following code:String s1 = \"abcd\";String s2 = \"abcd\";On line 2, the Java compiler will find \"abcd\" string literal in a String pool and provide reference to s2.Here is a diagram that presents this memory allocation:graph LRs1 --&gt; V[''abcd'']s2 --&gt; V[''abcd'']subgraph Stacks1 &amp; s2endclassDef subgraph_padding fill:none,stroke:nonesubgraph HeapV subgraph 1 [ ] subgraph SP[String pool] V end endendclass 1 subgraph_paddingUsing String ConstructorIs there a way to make a string on the heap outside String pool?Yes, using String constructor. When we create a String via the new operator, the Java compiler will create a new object and store it in the heap space reserved for the JVM.If we expand once more on our example:String s1 = \"abcd\";String s2 = \"abcd\";String s3 = new String(\"abcd\");String s4 = new String(\"abcd\");Its memory allocation would be the following:graph LRs1 --&gt; V[''abcd'']s2 --&gt; V[''abcd'']s3 --&gt; V3[''abcd'']s4 --&gt; V4[''abcd'']subgraph Stacks1 &amp; s2 &amp; s3 &amp; s4endclassDef subgraph_padding fill:none,stroke:nonesubgraph Heap subgraph 1 [ ] subgraph SP[String pool] V end endV &amp; V3 &amp; V4endclass 1 subgraph_paddingManual InterningThere is a way to manually intern a string in the String pool by using intern() method on the string object itself.String s1 = new String(\"abcd\");String s1Interned = s1.intern();After line 1:graph LRs1 --&gt; V[''abcd'']subgraph Stacks1endclassDef subgraph_padding fill:none,stroke:nonesubgraph HeapV subgraph 1 [ ] subgraph SP[String pool] subgraph 2 [ ] ''abcd'' end end endendclass 1 subgraph_paddingclass 2 subgraph_paddingNote that on line 1 the string literal itself must be interned.After line 2:graph LRs1 --&gt; V[''abcd'']s1Interned --&gt; VInterned[''abcd'']subgraph Stacks1 &amp; s1InternedendclassDef subgraph_padding fill:none,stroke:nonesubgraph HeapV subgraph 1 [ ] subgraph SP[String pool] VInterned end endendclass 1 subgraph_padding Beware that call to String.intern() manually is time-consuming. Note on String pool for older Java versions It is true that String pool is allocated on the heap memory starting from Java 7. Before that, it was placed in PermGen, which has a fixed size. Since it has a fixed size, we could get OutOfMemory exception if we were to intern too many Strings. Since Java 7, the String pool is stored in the heap, which is garbage collected by the JVM. As it is part of the heap, Garbage Collector will clear unused strings and it reduces the risk of getting OutOfMemory exception. Furthermore, this memory can be expanded if we anticipate heavy use of strings in our application.String immutabilityNow that we covered the inner mechanisms of String pool we can better understand decision for making String class immutable. Here are the main reasons for such a decision: String pool would not be possible if the string was not immutable. We already mentioned that Java is optimizing memory use by supplying the same reference to all variables that use that particular string. In case the string is mutable, it would mean that value for all variables in the program would change if they were all using the same instance. Security is one of the reasons why it‚Äôs good that string is immutable. Any credentials like username/password for accessing DBs, or other configuration parameters should be unchanged once provided to the application. Multithreading is easy with strings, since they are immutable, as we don‚Äôt have to worry about sharing strings between multiple threads. Strings are thread-safe by design. One advantage of being immutable is that calculation of a hashcode is done only once - at the time of the creation of a string. Because of that, strings are great for use in HashMap as a key and they are the most used key in HashMap actually.String concatenationJava is doing automatic intern of string literals and their concatenations, but not a concatenation of string literal with a String object. Let‚Äôs see this example:String s1 = \"ab\" + \"cd\"; // internedString s2 = \"ab\"; // internedString s3 = s2 + \"cd\"; // not interneds3 = s3.intern(); // explicit internPerformance of string concatenationWhen using a concatenation of strings in Java, with each concatenation, the following steps are made: Contents of both strings are copied New StringBuilder object is created and appended with both strings The string is returned via toString() method of the StringBuilder objectExample:String s = \"\";s += \"a\";s += \"b\";s += \"c\";s += \"d\";In this example, all mentioned steps are performed 4 times for each concatenation.Time complexity is O(n^2) because we need to copy the previously created string in each iteration. Also, it‚Äôs space demanding as well, since a new instance of StringBuilder class is created for each concatenation.Instead of using + operator, it‚Äôs recommended to use StringBuilder. It‚Äôs roughly 300 times faster than using + operator.This does not mean that you need to use StringBuilder all the time. It‚Äôs ok to use + operator, but if you encounter heavy text processing tasks, you could have a significant performance boost if you utilize StringBuilder instead.Other pools?In Java there is also Integer constant pool, which behaves in a same way as a String pool, but with a limitation.As per Java documentation it says: This method will always cache values in the range -128 to 127, inclusive, and may cache other values outside of this rangeInteger i1 = 10;Integer i2 = 10;// will return trueSystem.out.println(i1 == i2);Integer i3 = 410;Integer i4 = 410;// should return falseSystem.out.println(i3 == i4);As Integer is object, it should be compared using equals() and not == operator. The other way is to unbox it to int primitive.What about other programming languages?As you would expect, not only Java uses String pool, it can be found in other programming languages such as Python, Ruby, C#, Javascript‚Ä¶They have implementations of their own, but actually, the concept is the same." }, { "title": "Character Encoding Demystified: Everything you Need to Know About ASCII, Unicode, UTF-8", "url": "/posts/character-encoding-demystified/", "categories": "encoding", "tags": "encoding, ascii, unicode, utf-8, utf-16, string, crlf", "date": "2022-07-16 11:50:00 +0200", "snippet": "Have you ever wondered how exactly a computer stores letters like A, B, C‚Ä¶ or Chinese characters like ÂêÉ, or even some emojis like üòÜ and üöÄ?Maybe you are familiar with ASCII and you are aware of Unicode, but you don‚Äôt know exactly how it works?In this article, we‚Äôll cover the basics of character encoding and several encoding schemes and introduce some fundamental concepts on the way.Evolution of data transmissionBack in the day, when people wanted to communicate over great distances, they had limited options. They could write messages in a form of mail letters and send them over via post service or even use pigeons to fly and carry them over.But still, there was a need for immediate communication in cases of emergency like the warning of bad weather, or military communication.Over time different civilizations developed quite a few techniques of communication such as smoke signals, church bells, whistling, reflecting sunlight with mirrors, etc. All of these were limited in their capabilities and were generally not suitable for transferring arbitrary messages. They were mostly used to signal if there is some kind of danger ahead or call for help.Improved ways of communicating arbitrary messages are called Telegraphy. Telegraphy is the long-distance transmission of messages where the sender uses symbolic codes, known to the recipient, rather than a physical exchange of an object bearing the message.Some of the most used and famous telegraph systems are the Morse code and Flag semaphore (used in maritime and aviation even in the present time).As good as they are, these systems were not suitable for computer processing.Character encoding Encoding is a way to convert data from one format to another.As we all know, computer stores data in a binary format, i.e. ones and zeros. So, to store textual data in computer memory, or transfer it over a digital network, we need a way to represent textual data in a binary format that the computer understands.A single unit of textual data is called a character (or char in most programming languages). For now, it‚Äôs enough to know that char can be any sign used for creating textual content, such as a letter of the English alphabet, digit, or some other signs like space, comma, exclamation mark, question mark, etc. A character encoding is a way to convert text data into binary numbers.Essentially, encoding is a process of assigning unique numeric values to specific characters and converting those numbers into binary language. These binary numbers later can be converted back (or decoded) to original characters based on their values. Character set is simply a mapping between binary numbers and characters.Simply put, character set is an agreement that defines the correlation between binary numbers and characters from a character set.Creating character setWhat would you do if you were to make up your character set for the English language?Probably you would take all letters from the English alphabet both upper and lower case:AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZzThen, you would add digits as well:0123456789Also, you would need space, comma, semicolon, and other signs that complement letters and digits:&lt;space&gt;!\"#$%&amp;'()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~If you count these up, you will get 95 distinct characters:AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz0123456789 !\"#$%&amp;'()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~To represent 95 characters, we need at least 7 bits, which allows us to define 2^7 = 128 characters.Now, we can make up a table that will contain the mapping between each binary number and character from the set we just defined.We could make A = 0000 0001, B = 0000 0010 and so on‚Ä¶ Or in any other way we like.What are fonts ü§î?Most surely you heard of and used many different fonts on a computer. It must be obvious by now, that the character set is only defining what is sent, not how it looks.When we are referring to a character as ‚ÄúA‚Äù or ‚ÄúB‚Äù, we have a common understanding of what it means (it‚Äôs the Platonic ‚Äúidea‚Äù of a particular character). But we can all read and write the same characters in different variations (shapes).A font is a collection of glyph definitions, in other words, the shapes (or images) that are associated with the character they represent.Simple as that üôÇ.ASCIIWe‚Äôve shown that at least 7 bits are needed to represent characters used for creating textual content in the English alphabet.As with most things in engineering, character sets (encodings) should be standardized.One such (most famous) 7-bit encoding is ASCII (based on Telegraph code).ASCII table has arranged characters in a very elegant fashion.For example, all the uppercase and lowercase letters are in their alphabetical order. The same goes for digits.You can easily learn ASCII code for the character A, character a and character 0 because they are arranged in such an elegant way: Character A starts with 1, followed by all zeros and 1 (as the first letter in the alphabet) at the end: 100 0001 Lower case letters have the same ASCII codes as upper case letters, with the second digit being 1 instead of 0. It‚Äôs easy now to find a - just take A 1000001 and flip the second digit to 1, you get 110 0001 Digit zero is 010 0000A summary of these characters is given here in a table: Character Binary representation Rule A 100 0001 Starts with 1, has all zeros, and 1 at the end a 110 0001 Starts with 11, has all zeros and 1 at the end 0 010 0000 Starts with 01, has all zeros Now you can derive any other letter/digit by simply counting up to the one you need.CR and LFExtra 35 spaces were used to represent some special, so-called ‚Äúcontrol‚Äù characters.Some would be BS (backspace), DEL (delete), TAB (horizontal tab).Let‚Äôs take a look at two particularly interesting examples. Namely, telegraph machines would require 2 operations to go to the next line when printing text:CR - Carriage returnLF - Line feedIt‚Äôs based on manual typewriter machines like this one:When you type text and come to the right end of the page, you would like to go to the next line.So, you would first push the handle on the left side (marked as 1 on the picture) to the right to move the carriage, hence CR (Carriage return).The next step is to ‚Äúfeed‚Äù the typewriter with more next line of paper with a knob either on the right end of the carriage (market as 2 on the picture). Hence, LF (Line feed).This brought confusion to users of different OS, as there is no standardized end-of-line notation: Operating system End-of-line notation Linux LF Windows CR LF MAC (up through version 9) CR MAC OS X LF In most programming languages non-printable characters are represented using so-called escaped character notation, usually with a backslash character \\.Some examples are given here: Character Escaped CR \\r LF \\n TAB \\t ASCII encoding exampleLet‚Äôs now try to encode text Hello World! in ASCII.It would get you something like this: Character Dec Hex Binary H 72 48 100 1000 e 101 65 110 0101 l 108 6c 110 1100 l 108 6c 110 1100 o 111 6f 110 1111 &lt;space&gt; 32 20 010 0000 W 87 57 101 0111 o 111 6f 110 1111 r 114 72 111 0010 l 108 6c 110 1100 d 100 64 110 0100 ! 33 21 010 0001 What about the 8th bit?A byte is the smallest unit of storage that a computer would use. You may think that since the beginnings of the computing era byte was always 8 bits long. But that is not the case, as you can see with ASCII, which uses 7 bits. ASCII was standardized in 1963, but the first commercial 8-bit CPU came out in 1972. And as late as 1993 it was formally standardized that a byte is 8 bits long.For modern CPUs byte is 8 bits long, so when storing ASCII characters, you are left with one extra bit.All original text encoded with 7-bit ASCII can be encoded in 8-bit simply by appending 0 to the left side of the binary code, so its decimal and hexadecimal value stay the same.Now, taking our last example we can finally write it in the 8-bit format:H e l l o &lt;space&gt; W o r l d !01001000 01100101 01101100 01101100 01101111 00100000 01010111 01101111 01110010 01101100 01100100 00100001One question arises here: can we somehow leverage this extra bit ü§î?This 8th bit allows us to have another 128 spaces for new characters, right?Extended ASCII (Code pages)Encodings that are using same mappings for ASCII printable characters are called Extended ASCII and are commonly referred to as Code pages. They guarantee that all ASCII encoded files can be processed with these extended encodings. One popular 8-bit encoding scheme that was not ASCII compatible is EBCDIC, which was used on proprietary IBM PCs.Instead of just one, we have a huge number of standardized code pages. A full list of code pages can be found on Wikipedia: https://en.wikipedia.org/wiki/Code_pageSome of the most known are: Window-1252 (or ANSI-1252) - default code page for legacy Windows OS CP437 (also known as OEM 437, or DOS Latin the US) - an original code page for IBM PC. ISO-8859-1, aka Latin-1 (also useful for any Western European language) Now, if you wanted to write textual content using Cyrillic you would use Windows-1251 encoding. When you transmit this data, the other party would need to use the same encoding scheme (code page) to successfully read the data they received. If the encoding scheme is not the same, the text would appear as if written in a different language.If not explicitly set, ISO 8859‚Äì1 was the default encoding of the document delivered via HTTP with the MIME Type beginning with text/. Since HTML5 this was changed to UTF-8.UnicodeCode pages solved only part of the problem - storing additional characters for other languages since ASCII was designed to be sufficient for the English alphabet.For most European languages this was acceptable, but not a great solution. You could not for example write in multiple languages in the same textual file, because you can use only one code page while processing text.A bigger issue than that was the lack of support for languages that have much more characters than available 128 spaces within ASCII extended 8-bit code pages. Some examples are Arabic, Hindu, and Chinese (which have more than 10 thousand symbols called ideograms, which are actual words rather than letters as we are used to in European languages for example).In a response to all the problems ‚Äúcode pages‚Äù had been introduced, and a new standard was initiated named Unicode. It was an attempt to make a huge single character set for all spoken languages and even some made-up ones and other signs such as emojis üéâ. The first version came out in 1991 and had many new versions since then, the latest one being in 2021 at the time of this writing. The Unicode Consortium also maintains the standard for UTF (Unicode Transformation Format) encodings. More on this later. But first‚Ä¶Grapheme and code pointUp until now, we described all characters as self-contained symbols that can be represented with a single binary number in the encoding schema.In simple words, the letter A is just encoded with some binary number (0100 0001 in ASCII).But, things got a lot more complicated when considering other languages.Some languages have modifiers of the letters such as accent modifiers. One such example that is also used in the English language for some foreign words is √â (e-acute) which is an ordinary E letter with the acute symbol (that forward slash above the letter). Diacritic - extra decoration for the characterGrammar of some languages requires the use of diacritics for letters when certain conditions are met. Therefore, term character became ambiguous, so a new term is adopted for describing written symbols that could be with or without diacritics - a grapheme. Grapheme is a single unit of human writing system. It may consist of one or more code points.As there can be a huge number of combinations of letters and their possible modifiers, instead of making an encoding schema for all of them, it‚Äôs much more efficient to encode them separately. Therefore we separate grapheme in code points. Code point is any written symbol or it‚Äôs modifier like diacritic for letters, or even skin color of emojisSo, one or more code points can make up a grapheme. Therefore, the Unicode character set is defined as a set of code points rather than a set of graphemes.Some people believe that Unicode is just a simple 16-bit code where each character is mapped to a 16-bit number and so there are 2^16 = 65 536 possible code points. That is not the case and there are 144 697 defined characters at the time of writing this article.What is true is that all characters that can fit into 2 bytes, in other words, 2^16 = 65 536 code points are considered to make up BMP - basic multilingual plane (U+0000 to U+FFFF). This was the first attempt to unite all code points needed for storing textual data, but soon it became obvious that it needed even more space, so 2 bytes were not sufficient anymore.Let‚Äôs go back to √â for a moment. This particular symbol can be encoded in two ways: using one code point that represents character √â (U+00C9) using two code points, one for the letter E (U+0065) and its accent modifier (U+02CA) Codepoint notationAs we‚Äôve seen, the usual notation for Unicode characters is following:U+XXYY U+ stands for Unicode XXYY are bytes expressed in hexadecimal numbers (can be two or more)If we go back to √â described as 2 code points, we can easily track the first code point as hexadecimal 65, which is indeed the letter E in the ASCII table.Some graphemes have more than 2 bytes. For example thumbs up emoji üëç has the notation: U+1F44D.Unicode encoding strategiesASCII has a very simple encoding scheme. As it uses only one byte, it‚Äôs very easy to map all characters to binary format and vice-versa.For Unicode, things are not that simple. There are varying lengths of code points, going from 1 up to 4 bytes in size.Next, we‚Äôll take a look at the most interesting encoding schemes for Unicode. There are two groups of schemes: UCS - Universal Character Set UTF - Unicode Transformation FormatThere are similarities and differences between them. We‚Äôll cover the most relevant in this article.UTF-32 and UCS-4As the name suggests, UTF-32 consists of 32 bits, i.e. 4 bytes. This is the simplest encoding strategy. Every code point is converted to a 32-bit value. We‚Äôll see in short why this strategy is not very efficient in terms of space.UCS-4 is the same in every aspect as UTF-32.Let‚Äôs go back to our example from the beginning of this article with a simple change: let‚Äôs add emoji üöÄ between world and !:Hello worldüöÄ! Character Hex H 00 00 00 48 e 00 00 00 65 l 00 00 00 6c l 00 00 00 6c o 00 00 00 6f &lt;space&gt; 00 00 00 20 W 00 00 00 57 o 00 00 00 6f r 00 00 00 72 l 00 00 00 6c d 00 00 00 64 üöÄ 00 01 F4 4D ! 00 00 00 21 Do you notice something? For the majority of the content, we use much more space than needed. All ASCII characters require just one byte of space, but here we are spending additional 3 bytes per code point, which are all zeros. In other words, UTF-32 wastes a lot of memory for ASCII characters. If the text consists of only ASCII characters, UTF-32 would be 4X larger than the ASCII representation of the same text!One advantage that UTF-32 has over other Unicode encoding schemes is that because of its simplicity, it‚Äôs easy to index code points in a file. As you only need to go 4 bytes per code point, so you can go to the desired index very fast, in both the forward and backward directions.What happens case when the ASCII text processor tries to read out UCS-4 encoded string? In ASCII text processors, the end of a string is usually presented with 0x00, which means that string is going to be terminated once it comes across a byte that has all zeros. So, it would not read the text till the end if it consists of code points that are less than 4 bytes in size.UTF-32/UCS-4 is not in use anymore by modern text processors, instead, you will find UTF-16 or UTF-8.UCS-2Remember BMP (Basic Multilingual Plane)? We said that all characters that fit into 2 bytes are considered to be part of BMP. UCS-2 was exactly that - 2 bytes per code-point and nothing more!As this was an improvement over 8-bit code pages, it‚Äôs still not enough to represent more and more demanding and ever-expanding Unicode character set, so it quickly became obsolete in favor of a more flexible, yet very similar UTF-16 encoding scheme.Here is a quick overview of support for code points using different encoding schemes: Code point Binary value ASCII support UCS-2 support UTF-32 / UTF-16 / UTF-8 support E 01000101 ‚úÖ ‚úÖ ‚úÖ Œ¶ 00000011 10100110 ‚ùå ‚úÖ ‚úÖ üöÄ 00000000 00000001 11110110 10000000 ‚ùå ‚ùå ‚úÖ UTF-16This encoding scheme uses either 2 or 4 bytes to represent a single code point, so it‚Äôs not limited to UCS-2 to only 65 536 code points.The majority of the code points that takes up to 16 bits can be directly converted in the same way as UCS-2 is doing - just a simple binary representation of the code point hexadecimal value.The mechanism it uses is called surrogate pairs.Surrogate pairsIt‚Äôs easier to look at an example of how a code point is encoded with the UTF-16 encoding scheme.Let‚Äôs take emoji like üöÄ that has Unicode value U+1F680.Its binary form is:00000000 00000001 11110110 10000000Now, we see that it goes over 16 bits in size. To represent a character of more than 16 bits in size, we need to use a ‚Äúsurrogate pair‚Äù, with which we get a single supplementary character. The first (high) surrogate is a 16-bit code value in the range U+D800 to U+DBFF, and the second (low) surrogate is a 16-bit code value in the range U+DC00 to U+DFFF.High surrogate format: 110110XX XXXXXXXXLow surrogate format: 110111XX XXXXXXXX High and low surrogate pairs exist so we can know if we are in the middle of the character when parsing data encoded in UTF-16.Now, we need to subtract 1 00000000 00000000 from the binary representation of emoji. 00000000 00000001 11110110 10000000- 00000000 00000001 00000000 00000000= 00000000 00000000 11110110 10000000Then, we are going to take the lower 20 binary digits:0000 11110110 10000000And replace X signs in high and low surrogate with bits we just calculated:0000 11110110 10000000// Split in half:00 0011110110 10000000// Replace Xs in High and Low surrogateHigh surrogate mask: 110110XX XXXXXXXXLow surrogate mask: 110111XX XXXXXXXXHigh surrogate value: 11011000 00111101Low surrogate value: 11011110 10000000And there you have it! Emoji üöÄ is represented in UTF-16 encoding schemes with 4 bytes:11011000 00111101 11011110 10000000Unicode restricted code pointsIt‚Äôs important to note that since we are using surrogate pairs for marking 4-byte UTF-16 code points, we cannot use ranges for a high and low surrogate for 16-bit code points:High surrogate unavailable range: 11011000 00000000 (D800) to 11011011 11111111 (DBFF)Low surrogate unavailable range: 11011100 00000000 (DC00) to 11011111 11111111 (DFFF)You can notice that these two ranges makes one continuous range:Surrogate unavailable range: 11011000 00000000 (D800) to 11011111 11111111 (DFFF)In this range, there are no code points, in other words, this hole makes 2^11 = 2048 unavailable code points.Because of these restrictions, designers of the Unicode standard decided to exclude the same range of code points from UCS-2, so UTF-16 is fully compatible with UCS-2 for all 2-byte-sized code points.This restricted range is the same for all Unicode encodings.Unicode tableThe site https://unicode-table.com/ contains a lot of useful information regarding Unicode characters. We can even check the info page for üöÄ emoji here: https://unicode-table.com/en/1F680/ to verify we get the correct value for our example for UTF-16 encoding.Here we can see basic info, like: Unicode value HTML code (essentially a decimal value) CSS-code (hexadecimal value in a different format than Unicode notation)Near the end of the page, you can check out Encoding values for this Unicode code point:As you can see, we successfully calculated UTF-16 encoding, yeah ü•≥!But wait, you might ask what are now these 2 variations of UTF-16 called UTF-16BE and UTF-16LE ü§î? That brings us to the next topic‚Ä¶..EndiannessThe order of the bytes for multi-byte in which they are stored in memory is called Endianness of the computer system. Depending on the place of the MSB (Most Significant Byte) and LSB (Least Significant Byte) there are: BE - Big-endian (MSB is stored at the smallest memory address) LE - Little-endian (LSB is stored at the smallest memory address)Why does this matter in the first place?CPU usually does not take one byte when processing data, but it takes multiple bytes. This measure is called word in CPU terminology. It becomes natural that the size word is multiple of 8 since the smallest unit for storage is byte (8 bits). Modern CPUs are 32-bit or 64-bit in size.Most modern computer systems (Intel processors for example) use a little-endian format to store the data in the memory. The reason is beyond the scope of this article, but it‚Äôs related to the internal structure of the CPU since particular endianness allows for certain features on different CPU designs.If we have 32-bit integer number like 42 for example, we would write it in binary format as:// Big EndianMSB LSB0000 0000 | 0000 0000 | 0000 0000 | 0010 1010 &lt;- binary representation0x00 | 0x01 | 0x02 | 0x03 &lt;- memory address// Little EndianLSB MSB0010 1010 | 0000 0000 | 0000 0000 | 0000 0000 &lt;- binary representation0x00 | 0x01 | 0x02 | 0x03 &lt;- memory addressNow, you can see that if we didn‚Äôt know what was the endianness, we could interpret this integer number in the wrong way.For our example, instead of reading 42, we could by mistake think it‚Äôs 704 643 072!Now that you understand the implications of using the wrong endian in processing data, let‚Äôs go back to Unicode.Text processors need to know how to parse the text. That‚Äôs where Endianness comes into the picture.All Unicode encodings use at least 2 bytes of data per code point, meaning that the CPU is storing multiple bytes at once in either BE or LE.BOM - Byte Order MarkA little trick we can use to make sure proper endianness is applied when reading files written in Unicode encodings is the so-called Byte Order Mark or BOM for short.Let‚Äôs take a look at the UTF-16 example.BOM is nothing more than a code point that has a special property.Its Unicode value is U+FEFF and it represents ‚Äúzero-width, non-breaking space‚Äù.What that means is this code point is not visible on screen, yet it is a valid code point for UTF-16 encoding.But, the catch is that if we reverse the order of the bytes to U+FFFE we get to a value that is considered invalid for UTF-16 encoding. Hence, the text processor understands that it needs to read the bytes in a different order, using Little Endian.What a nice little trick üôÇ!To use BOM, these 2 bytes will be saved at the beginning of a file, so the text processor can immediately figure out what Endianness is used for the file.Now, to demonstrate this, I will show how it looks when saving characters abcde in a file using UTF-16 LE and UTF-16 BE:// When saved as UTF-16 LE it will keep LSB on lowest memory address FF FE 61 00 62 00 63 00 64 00 65 00// When saved as UTF-16 BE it will keep LSB on lowest memory address FF FE 61 00 62 00 63 00 64 00 65 00 If BOM is not set for UTF-16, it is assumed that Big endian is used.UTF-8This brilliant encoding scheme is one of the most used today alongside UTF-16, because of its very useful features.Code points that take 1 byte of size and are encoded with the same scheme as ASCII encoding. For all other code points, UTF-8 uses from 2 up to 4 bytes (even 6 in some cases), depending on the code point itself.What this encoding allows as a bonus is backward compatibility with ASCII encoded files, as all ASCII characters would be read properly. This is not the case with UTF-32, UTF-16, and UCS-2 encoding schemes, as they expect the exact number of bytes per code point (4 for UTF-32, 2 for UCS-2 and 2-4 for UTF-16).Also, programs that use ASCII encoding can read files written in the UTF-8 schema, as long as they used only ASCII characters.What is the downside of the UTF-8 encoding scheme? It should be obvious by now, that it‚Äôs the fact that code points are variable in size, so it‚Äôs hard to index code points in a file (in other words searching for the n-th character in the file), in contrast to UTF-32 and UTF-16 encoding schemes.Another downside is that it uses 50% more space than UTF-16 for East Asian text.UTF-8 also has the nice property that ignorant old string-processing code that wants to use a single 0 byte as the null-terminator will not truncate strings, as is the case with other encoding schemes.UTF-8 encoding algorithmThe encoding algorithm that is used for UTF-8 is very simple, yet brilliant!It can be summarized in the following rules: If the code point is in the range of ASCII characters, it is encoded in the same way as ASCII. Simple as that! For other characters, we need to use more than one byte, in the following way: The first byte must start with the same number of zeros as the number of bytes that will be used for this code point, followed by a zero. Every other byte must start with 10. Once we create such masked bytes, we fill in the binary form of the code point in data spaces. As this was a mouthful, let‚Äôs go over some examples to better understand this process.Example 1Character A falls in a range of ASCII characters. Therefore, it‚Äôs encoded using ASCII encoding like this:01000001Example 2Greek letter Œ¶ has a Unicode code point U+03A6.Its binary form is:00000011 10100110As we can see, it has more than 7 bits in size, hence we need to use step 2. in the algorithm for encoding this code point to UTF-8.Let‚Äôs check if 2 bytes will be enough to encode this code point. In such a case, the first byte will have the following mask:// Number of ones == number of bytes, then 0110XXXXXNext byte would have a mask:10XXXXXXIf we count up X signs, we see that we have 11 spaces for binary representation of Unicode code point.As our code point from example, Œ¶ can fit in 10 binary digits, 2 bytes is enough for this code point.What is left to do is to replace masks with binary digits that represent our Unicode code point:11001110 10100110Or, in hexadecimal, we get CE A6.If you check https://unicode-table.com/en/03A6/, you can verify we got the correct value. Yeah ü•≥!Example 3For the final example, let‚Äôs take one more look at the üöÄ emoji.Binary form:00000000 00000001 11110110 10000000As this one needs 17 bits, it will not fit in 2 bytes for the UTF-8 encoding.It will not fit into 3 bytes as well, because:1110XXXX 10XXXXXX 10XXXXXXThis gives us 16 bits of space, but we need 17.So, we need 4 bytes:11110XXX 10XXXXXX 10XXXXXX 10XXXXXXThis gives us 3x6+3 = 21 bits of space for Unicode code points.Now, let‚Äôs populate masked bits and we get:11110000 10011111 10011010 10000000Which is F0 9F 9A 80 in hexadecimal. You can verify it here: https://unicode-table.com/en/1F680/UTF-8 encoding summaryHere is a summary of code point ranges and their respective UTF-8 byte sizes: Bits of code point First code point Last code point Bytes in sequence Byte 1 Byte 2 Byte 3 Byte 4 Byte 5 Byte 6 7 U+0000 U+007F 1 0xxxxxxx ¬† ¬† ¬† ¬† ¬† 11 U+0080 U+07FF 2 110xxxxx 10xxxxxx ¬† ¬† ¬† ¬† 16 U+0800 U+FFFF 3 1110xxxx 10xxxxxx 10xxxxxx ¬† ¬† ¬† 21 U+10000 U+1FFFFF 4 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx ¬† ¬† 26 U+200000 U+3FFFFFF 5 111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx ¬† 31 U+400000 U+7FFFFFFF 6 1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx What about BOM for UTF-8?For UTF-8 there is also a possibility to define BOM in the same way as for UTF-16.We know that BOM code point is FE FF. Binary form is:11111110 11111111As we‚Äôve seen in an exercise just before, since this code point is more than 8 bits in size, we need to use multiple bytes. In this case, we need to use 3 bytes, as it gives us 16 bits of space, which is exactly how much we need to represent this code point.We already know that the first byte must start with several ones that represent how many bytes this code point requires by UTF-8 encoding (in this case 3), followed by zero. For other bytes, they must start with 10:// First byte mask1110xxxx// Other bytes masks10xxxxxx10xxxxxxSo, complete mask for our FE FF code point is:1110xxxx 10xxxxxx 10xxxxxxNow what is left is to populate x signs with bits themselves. We finally get:11101111 10111011 10111111Or, in hexadecimal:EF BB BFIf file is saved in UTF-8 with BOM encoding scheme, it‚Äôs first three bytes will be:// Big EndianEF BB BF// Little EndianBF BB EFHere is another demo of a file saved in UTF-8 BOM encoding: As is the case with UTF-16, if BOM is not present, assumed is Big Endian.Programming languages character encodingsIn most tutorials for beginners in any programming language, you learn how to print out the console famous ‚ÄúHello world!‚Äù sentence.As it would be overkill for a beginner student to learn all about character encodings, this information is usually left out.But it‚Äôs very important to know that not all programming languages are Unicode aware (meaning they operate on a sequence of Unicode characters rather than ASCII characters).Here is a list of some mainstream programming languages and their default character encodings: Programming language Default character encoding Unicode aware C/C++ ASCII ‚ùå Java UTF-16 (first versions used UCS-2) ‚úÖ C# UTF-16 ‚úÖ Javascript UTF-16 ‚úÖ PHP ASCII ‚ùå Python 2 ASCII ‚ùå Python 3 UTF-8 ‚úÖ This overview shows only the default character encoding used by these programming languages, it does not mean they cannot process Unicode text. They all have support for Unicode, either through additional data types or 3rd party libraries.The key point to take away from here is that you should be aware of the limitations your programming language has when processing data, otherwise you can get in all kinds of funny situations. For example, counting the number of characters in Unicode text that has at least one character outside the ASCII range using C++ char datatype would give you the wrong result.DB Unicode supportFor most DB engines there are, either SQL or NoSQL, there are settings per-database level where you can choose character encoding by yourself.All modern DB engines have support for Unicode, but you need to be cautious when choosing encoding schema.MySQLFor example, there is a case of MySQL server that has an encoding scheme called ‚Äúutf8‚Äù, which is just an alias for ‚Äúutfmb3‚Äù. What it represents is UTF-8 with Maximum Bytes 3.As shown in section ‚ÄúUTF-8 encoding summary‚Äù, we can see that with 3 bytes you can store only a range from U+0000 up to U+FFFF, so-called BMP (Basic Multilingual Plane). In MySQL, the encoding scheme ‚Äúutf8‚Äù cannot store Unicode code points outside Basic Multilingual Plane!Therefore, the recommended character encoding is ‚Äúutf8mb4‚Äù, which allows up to 4 bytes in size.Transmitting strings over the networkWhen sending data over a network, the recipient does not know the character encoding used to create that data. So, if you don‚Äôt specify it somehow, the recipient can only guess what encoding to use to read the content.E-mail encodingWhen sending e-mail messages you should (e-mail client actually) write a Content-Type HTTP header. It is used to indicate MIME type, where text can be one of the values. An example of UTF-8 encoding would be:Content-Type: text/plain; charset=\"UTF-8\"HTML encodingAs for the HTML pages, the encoding scheme is set up inside the same HTML file, with a special tag.&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt;...Now you may wonder how a text processor (in this case web browser) can even read the first part of the HTML without knowing the character encoding used?If you take a look at the code we just wrote, you can notice that all the characters used in this part of the file are in a range of ASCII printable characters. That allows for any ASCII-compatible encoding scheme (the vast majority of encoding schemes in use today) to read this part of the file.After the charset is read by a web browser, it can switch to a different encoding scheme if needed. meta tag for declaring charset in HTML should be the first thing in &lt;head&gt; tag, for 2 reasons: if something other than ASCII comes before this meta tag, you compromise the browser‚Äôs ability to read the proper charset and therefore the page can appear ‚Äúbroken‚Äù. as soon as the browser read the charset it will stop parsing the page and it will start from the beginning using the specified encoding scheme. You may ask what happens if there is no charset defined in HTML? Did the browser try to guess the encoding, or it will just use some default encoding scheme? Well, browsers do try to guess the encoding based on statistics on how many times particular characters appear in a text. As you may assume, it was not very successful in achieving a good result." }, { "title": "Welcome to my blog", "url": "/posts/welcome-to-my-blog/", "categories": "", "tags": "", "date": "2022-07-11 12:50:00 +0200", "snippet": "WelcomeHi there üëã Welcome to my Tech Blog! Hope you will find interesting articles for you and I am open to any suggestions you may have for new posts. You can contact me via social media or email in the left lower corner of website.Who am II‚Äôm Borko Rajkoviƒá, Software Engineer. I love to write code and discover new technologies.Check out About page for my technical background.What to expectThis blog will try to cover a variety of topics in Software Engineering, such as principles in programming, overview of different programming language features, discussions about databases (RDBMS and NoSQL), some tips and tricks and what not else üôÇ.FeedbackI would love to get feedback from you, so feel free to leave reaction and/or comment on each post I create.It will greatly help me to make this blog better üôè.Where to startThere will be posts on Home page, but feel free to search for category that is most interesting for you, or search by tags." } ]
